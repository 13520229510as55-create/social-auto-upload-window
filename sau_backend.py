# -*- coding: utf-8 -*-
import asyncio
import os
import sys
import sqlite3
import threading
import time
import uuid
import requests
from pathlib import Path
from queue import Queue
from datetime import datetime
from flask_cors import CORS
from myUtils.auth import check_cookie
from flask import Flask, request, jsonify, Response, render_template, send_from_directory
from conf import BASE_DIR

# Windows ç³»ç»Ÿè®¾ç½® UTF-8 ç¼–ç è¾“å‡º
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except AttributeError:
        # Python < 3.7 ä¸æ”¯æŒ reconfigure
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
try:
    from conf import HTTP_PROXY, HTTPS_PROXY
except ImportError:
    # å…¼å®¹æ—§ç‰ˆæœ¬ conf.pyï¼ˆæ²¡æœ‰ä»£ç†é…ç½®ï¼‰
    HTTP_PROXY = ''
    HTTPS_PROXY = ''
from myUtils.login import get_tencent_cookie, douyin_cookie_gen, get_ks_cookie, xiaohongshu_cookie_gen, bilibili_cookie_gen
from myUtils.postVideo import post_video_tencent, post_video_DouYin, post_video_ks, post_video_xhs, post_image_text_xhs
from urllib.parse import urlparse
import shutil

# è·å–ä¸­å›½æ—¶åŒºçš„å½“å‰æ—¶é—´ï¼ˆUTC+8ï¼‰
def get_china_time():
    """è·å–ä¸­å›½æ—¶åŒºçš„å½“å‰æ—¶é—´å­—ç¬¦ä¸²ï¼ˆæ ¼å¼ï¼šYYYY-MM-DD HH:MM:SSï¼‰"""
    # è·å–UTCæ—¶é—´ï¼Œç„¶ååŠ ä¸Š8å°æ—¶å¾—åˆ°ä¸­å›½æ—¶é—´
    from datetime import timedelta
    utc_now = datetime.utcnow()
    china_time = utc_now + timedelta(hours=8)
    return china_time.strftime('%Y-%m-%d %H:%M:%S')

active_queues = {}
# ä¿å­˜ç™»å½•è¿‡ç¨‹ä¸­çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆç”¨äºæ‰‹åŠ¨ç¡®è®¤ç™»å½•ï¼‰
active_browser_contexts = {}  # {account_id: {'browser': browser, 'context': context, 'page': page, 'account_name': name}}
app = Flask(__name__)

#å…è®¸æ‰€æœ‰æ¥æºè·¨åŸŸè®¿é—®
CORS(app)

# æ³¨å†Œ MediaCrawler çˆ¬è™«ç®¡ç†è“å›¾
# å¦‚æœä½¿ç”¨ FastAPI å¤„ç†çˆ¬è™«ç®¡ç†ï¼Œåˆ™ä¸æ³¨å†Œ Flask è“å›¾
if not os.getenv('USE_FASTAPI_FOR_CRAWLER'):
    try:
        from crawler_api import crawler_bp
        app.register_blueprint(crawler_bp)
        print("âœ“ MediaCrawler çˆ¬è™«ç®¡ç†è“å›¾å·²æ³¨å†Œï¼ˆFlask æ¨¡å¼ï¼‰")
    except ImportError as e:
        print(f"âš ï¸ MediaCrawler çˆ¬è™«ç®¡ç†è“å›¾æ³¨å†Œå¤±è´¥: {e}")
    except Exception as e:
        print(f"âš ï¸ MediaCrawler çˆ¬è™«ç®¡ç†è“å›¾æ³¨å†Œå‡ºé”™: {e}")
else:
    print("â„¹ï¸ çˆ¬è™«ç®¡ç†ä½¿ç”¨ FastAPIï¼ˆä¸ MediaCrawler ä¿æŒä¸€è‡´ï¼‰ï¼Œè·³è¿‡ Flask è“å›¾æ³¨å†Œ")

# å¯åŠ¨ Cookie è‡ªåŠ¨åˆ·æ–°å®šæ—¶ä»»åŠ¡ï¼ˆåœ¨åº”ç”¨åˆå§‹åŒ–æ—¶å¯åŠ¨ï¼‰
def start_cookie_refresh_scheduler():
    """
    å¯åŠ¨ Cookie è‡ªåŠ¨åˆ·æ–°å®šæ—¶ä»»åŠ¡
    æ¯ 2 å°æ—¶è‡ªåŠ¨åˆ·æ–°ä¸€æ¬¡æ‰€æœ‰è´¦å·çš„ cookie
    """
    try:
        import schedule
        from myUtils.cookie_refresh import run_cookie_refresh_task
        
        # æ¯ 2 å°æ—¶æ‰§è¡Œä¸€æ¬¡
        schedule.every(2).hours.do(run_cookie_refresh_task)
        
        print(f"[INFO] [{get_china_time()}] Cookie è‡ªåŠ¨åˆ·æ–°å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ï¼ˆæ¯ 2 å°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰", flush=True)
        
        def run_scheduler():
            """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œå®šæ—¶ä»»åŠ¡"""
            while True:
                schedule.run_pending()
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        
        # å¯åŠ¨åå°çº¿ç¨‹
        scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
        scheduler_thread.start()
        print(f"[INFO] Cookie åˆ·æ–°å®šæ—¶ä»»åŠ¡çº¿ç¨‹å·²å¯åŠ¨", flush=True)
        
    except ImportError as e:
        # æ¨¡å—ä¸å­˜åœ¨æ—¶ï¼Œé™é»˜è·³è¿‡ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
        print(f"[WARNING] Cookie åˆ·æ–°æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡å®šæ—¶ä»»åŠ¡: {str(e)}", flush=True)
    except Exception as e:
        print(f"[WARNING] å¯åŠ¨ Cookie åˆ·æ–°å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}", flush=True)
        import traceback
        traceback.print_exc()

# åœ¨åº”ç”¨åˆå§‹åŒ–æ—¶å¯åŠ¨å®šæ—¶ä»»åŠ¡
start_cookie_refresh_scheduler()

# é™åˆ¶ä¸Šä¼ æ–‡ä»¶å¤§å°ä¸º160MB
app.config['MAX_CONTENT_LENGTH'] = 160 * 1024 * 1024

# è·å–å½“å‰ç›®å½•ï¼ˆå‡è®¾ index.html å’Œ assets åœ¨è¿™é‡Œï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))

# å¤„ç†æ‰€æœ‰é™æ€èµ„æºè¯·æ±‚ï¼ˆæœªæ¥æ‰“åŒ…ç”¨ï¼‰
@app.route('/assets/<filename>')
def custom_static(filename):
    return send_from_directory(os.path.join(current_dir, 'assets'), filename)

# å¤„ç† favicon.ico é™æ€èµ„æºï¼ˆæœªæ¥æ‰“åŒ…ç”¨ï¼‰
@app.route('/favicon.ico')
def favicon(filename):
    return send_from_directory(os.path.join(current_dir, 'assets'), 'favicon.ico')

# ï¼ˆæœªæ¥æ‰“åŒ…ç”¨ï¼‰
@app.route('/')
def index():  # put application's code here
    return send_from_directory(current_dir, 'index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({
            "code": 200,
            "data": None,
            "msg": "No file part in the request"
        }), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({
            "code": 200,
            "data": None,
            "msg": "No selected file"
        }), 400
    try:
        # ä¿å­˜æ–‡ä»¶åˆ°æŒ‡å®šä½ç½®
        uuid_v1 = uuid.uuid1()
        print(f"UUID v1: {uuid_v1}")
        filepath = Path(BASE_DIR / "videoFile" / f"{uuid_v1}_{file.filename}")
        file.save(filepath)
        return jsonify({"code":200,"msg": "File uploaded successfully", "data": f"{uuid_v1}_{file.filename}"}), 200
    except Exception as e:
        return jsonify({"code":200,"msg": str(e),"data":None}), 500

@app.route('/getFile', methods=['GET'])
def get_file():
    # è·å– filename å‚æ•°
    filename = request.args.get('filename')

    if not filename:
        return {"error": "filename is required"}, 400

    # é˜²æ­¢è·¯å¾„ç©¿è¶Šæ”»å‡»
    if '..' in filename or filename.startswith('/'):
        return {"error": "Invalid filename"}, 400

    # æ‹¼æ¥å®Œæ•´è·¯å¾„
    file_path = str(Path(BASE_DIR / "videoFile"))

    # è¿”å›æ–‡ä»¶
    return send_from_directory(file_path,filename)


@app.route('/uploadSave', methods=['POST'])
def upload_save():
    if 'file' not in request.files:
        return jsonify({
            "code": 400,
            "data": None,
            "msg": "No file part in the request"
        }), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({
            "code": 400,
            "data": None,
            "msg": "No selected file"
        }), 400

    # è·å–è¡¨å•ä¸­çš„è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
    custom_filename = request.form.get('filename', None)
    if custom_filename:
        filename = custom_filename + "." + file.filename.split('.')[-1]
    else:
        filename = file.filename

    try:
        # ç”Ÿæˆ UUID v1
        uuid_v1 = uuid.uuid1()
        print(f"UUID v1: {uuid_v1}")

        # æ„é€ æ–‡ä»¶åå’Œè·¯å¾„
        final_filename = f"{uuid_v1}_{filename}"
        filepath = Path(BASE_DIR / "videoFile" / f"{uuid_v1}_{filename}")

        # ä¿å­˜æ–‡ä»¶
        file.save(filepath)

        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            # ç¡®ä¿è¡¨ä¸­æœ‰ source å’Œ uri å­—æ®µ
            try:
                cursor.execute("SELECT source FROM file_records LIMIT 1")
            except sqlite3.OperationalError:
                cursor.execute("ALTER TABLE file_records ADD COLUMN source TEXT DEFAULT 'æœ¬åœ°ä¸Šä¼ '")
            try:
                cursor.execute("SELECT uri FROM file_records LIMIT 1")
            except sqlite3.OperationalError:
                cursor.execute("ALTER TABLE file_records ADD COLUMN uri TEXT")
            
            cursor.execute('''
                                INSERT INTO file_records (filename, filesize, file_path, source)
            VALUES (?, ?, ?, ?)
                                ''', (filename, round(float(os.path.getsize(filepath)) / (1024 * 1024),2), final_filename, 'æœ¬åœ°ä¸Šä¼ '))
            conn.commit()
            print("âœ… ä¸Šä¼ æ–‡ä»¶å·²è®°å½•")

        return jsonify({
            "code": 200,
            "msg": "File uploaded and saved successfully",
            "data": {
                "filename": filename,
                "filepath": final_filename
            }
        }), 200

    except Exception as e:
        print(f"Upload failed: {e}")
        return jsonify({
            "code": 500,
            "msg": f"upload failed: {e}",
            "data": None
        }), 500

@app.route('/getFiles', methods=['GET'])
def get_all_files():
    """
    è·å–æ‰€æœ‰ç´ ææ–‡ä»¶
    æ”¯æŒç­›é€‰å‚æ•°: source (å¯é€‰ï¼Œå¦‚: 'ç”Ÿæˆç´ æ', 'æœ¬åœ°ä¸Šä¼ ', 'è°·æ­Œå­˜å‚¨ä¸Šä¼ ')
    """
    try:
        # è·å–ç­›é€‰å‚æ•°ï¼ˆå¤„ç†URLç¼–ç ï¼‰
        source_filter = request.args.get('source', '').strip()
        if source_filter:
            # å¦‚æœå‚æ•°æ˜¯URLç¼–ç çš„ï¼Œå°è¯•è§£ç 
            try:
                import urllib.parse
                source_filter = urllib.parse.unquote(source_filter)
            except:
                pass
        
        # ä½¿ç”¨ with è‡ªåŠ¨ç®¡ç†æ•°æ®åº“è¿æ¥
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row  # å…è®¸é€šè¿‡åˆ—åè®¿é—®ç»“æœ
            cursor = conn.cursor()

            # ç¡®ä¿è¡¨ä¸­æœ‰ source å’Œ uri å­—æ®µï¼ˆå…ˆæ£€æŸ¥å†æŸ¥è¯¢ï¼‰
            try:
                cursor.execute("SELECT source FROM file_records LIMIT 1")
            except sqlite3.OperationalError:
                cursor.execute("ALTER TABLE file_records ADD COLUMN source TEXT DEFAULT 'æœ¬åœ°ä¸Šä¼ '")
                conn.commit()
            try:
                cursor.execute("SELECT uri FROM file_records LIMIT 1")
            except sqlite3.OperationalError:
                cursor.execute("ALTER TABLE file_records ADD COLUMN uri TEXT")
                conn.commit()
            
            # æ ¹æ®ç­›é€‰æ¡ä»¶æŸ¥è¯¢
            if source_filter:
                cursor.execute("SELECT * FROM file_records WHERE source = ?", (source_filter,))
            else:
                cursor.execute("SELECT * FROM file_records")
            rows = cursor.fetchall()
            
            # å°†ç»“æœè½¬ä¸ºå­—å…¸åˆ—è¡¨ï¼Œå¹¶æå–UUID
            data = []
            for row in rows:
                row_dict = dict(row)
                # ä» file_path ä¸­æå– UUID (æ–‡ä»¶åçš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œä¸‹åˆ’çº¿å‰)
                if row_dict.get('file_path'):
                    file_path_parts = row_dict['file_path'].split('_', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿
                    if len(file_path_parts) > 0:
                        row_dict['uuid'] = file_path_parts[0]  # UUID éƒ¨åˆ†
                    else:
                        row_dict['uuid'] = ''
                else:
                    row_dict['uuid'] = ''
                # ç¡®ä¿ source å’Œ uri å­—æ®µå­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®¾ç½®é»˜è®¤å€¼
                if 'source' not in row_dict:
                    row_dict['source'] = 'æœ¬åœ°ä¸Šä¼ '
                if 'uri' not in row_dict:
                    row_dict['uri'] = None
                data.append(row_dict)

            return jsonify({
                "code": 200,
                "msg": "success",
                "data": data
            }), 200
    except Exception as e:
        return jsonify({
            "code": 500,
            "msg": str("get file failed!"),
            "data": None
        }), 500

@app.route('/saveGoogleStorageMaterial', methods=['POST'])
def save_google_storage_material():
    """ä¿å­˜è°·æ­Œå­˜å‚¨ä¸Šä¼ çš„ç´ æä¿¡æ¯"""
    try:
        data = request.get_json(silent=True) or {}
        
        # éªŒè¯å¿…å¡«å­—æ®µ
        required_fields = ['filename', 'filesize']
        missing_fields = [field for field in required_fields if not data.get(field)]
        if missing_fields:
            return jsonify({
                "code": 400,
                "msg": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}",
                "data": None
            }), 400
        
        filename = data.get('filename')
        filesize = data.get('filesize')
        uri = data.get('uri')  # URIæ˜¯å¯é€‰çš„
        custom_filename = data.get('custom_filename')  # å¯é€‰çš„è‡ªå®šä¹‰æ–‡ä»¶å
        
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æ–‡ä»¶åï¼Œä½¿ç”¨è‡ªå®šä¹‰æ–‡ä»¶å
        if custom_filename:
            final_filename = custom_filename
        else:
            final_filename = filename
        
        # ç”Ÿæˆ UUID v1
        uuid_v1 = uuid.uuid1()
        print(f"UUID v1: {uuid_v1}")
        
        # æ„é€  file_pathï¼ˆæ ¼å¼ï¼šuuid_filenameï¼‰
        file_path = f"{uuid_v1}_{final_filename}"
        
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            # ç¡®ä¿è¡¨ä¸­æœ‰ source å’Œ uri å­—æ®µ
            try:
                cursor.execute("SELECT source FROM file_records LIMIT 1")
            except sqlite3.OperationalError:
                cursor.execute("ALTER TABLE file_records ADD COLUMN source TEXT DEFAULT 'æœ¬åœ°ä¸Šä¼ '")
            try:
                cursor.execute("SELECT uri FROM file_records LIMIT 1")
            except sqlite3.OperationalError:
                cursor.execute("ALTER TABLE file_records ADD COLUMN uri TEXT")
            
            # æ’å…¥è®°å½•
            cursor.execute('''
                INSERT INTO file_records (filename, filesize, file_path, source, uri)
                VALUES (?, ?, ?, ?, ?)
            ''', (final_filename, filesize, file_path, 'è°·æ­Œå­˜å‚¨ä¸Šä¼ ', uri))
            conn.commit()
            print("âœ… è°·æ­Œå­˜å‚¨ä¸Šä¼ æ–‡ä»¶å·²è®°å½•")
        
        return jsonify({
            "code": 200,
            "msg": "Material saved successfully",
            "data": {
                "filename": final_filename,
                "filepath": file_path,
                "uuid": str(uuid_v1)
            }
        }), 200
        
    except Exception as e:
        print(f"Save Google Storage material failed: {e}")
        return jsonify({
            "code": 500,
            "msg": f"save failed: {str(e)}",
            "data": None
        }), 500

@app.route('/getGoogleFilePublicUrl', methods=['POST'])
def get_google_file_public_url():
    """è·å–è°·æ­Œå­˜å‚¨æ–‡ä»¶çš„å…¬å¼€è®¿é—®é“¾æ¥"""
    try:
        data = request.get_json(silent=True) or {}
        file_uri = data.get('uri')
        
        if not file_uri:
            return jsonify({
                "code": 400,
                "msg": "ç¼ºå°‘å¿…è¦å‚æ•°: uri",
                "data": None
            }), 400
        
        # ä»URIä¸­æå–æ–‡ä»¶ID
        # URIæ ¼å¼: https://generativelanguage.googleapis.com/v1beta/files/8kxw2l3kmzkh
        # æˆ–è€…: files/8kxw2l3kmzkh
        file_id = None
        if '/files/' in file_uri:
            file_id = file_uri.split('/files/')[-1]
        elif file_uri.startswith('files/'):
            file_id = file_uri.replace('files/', '')
        
        if not file_id:
            return jsonify({
                "code": 400,
                "msg": "æ— æ³•ä»URIä¸­æå–æ–‡ä»¶ID",
                "data": None
            }), 400
        
        # ä½¿ç”¨API Keyè·å–æ–‡ä»¶ä¿¡æ¯
        api_key = 'AIzaSyBWj4raKG-ayYkKOVP9eHSdpZO7oT7TuWo'
        file_info_url = f'https://generativelanguage.googleapis.com/v1beta/files/{file_id}?key={api_key}'
        
        try:
            response = requests.get(file_info_url, timeout=10)
            if response.status_code == 200:
                file_data = response.json()
                # è¿”å›æ–‡ä»¶ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¯èƒ½çš„ä¸‹è½½é“¾æ¥
                return jsonify({
                    "code": 200,
                    "msg": "success",
                    "data": {
                        "uri": file_uri,
                        "file_id": file_id,
                        "file_info": file_data,
                        # æ³¨æ„ï¼šGoogle Generative AI APIçš„æ–‡ä»¶éœ€è¦é€šè¿‡APIè®¿é—®ï¼Œæ²¡æœ‰ç›´æ¥çš„å…¬å¼€é“¾æ¥
                        # å¦‚æœéœ€è¦å…¬å¼€é“¾æ¥ï¼Œéœ€è¦å°†æ–‡ä»¶ä¸Šä¼ åˆ°Google Cloud Storageå¹¶è®¾ç½®å…¬å¼€æƒé™
                        "public_url": None,  # éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼è·å–
                        "api_access_url": file_uri  # APIè®¿é—®åœ°å€
                    }
                }), 200
            else:
                return jsonify({
                    "code": 500,
                    "msg": f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {response.status_code}",
                    "data": None
                }), 500
        except Exception as e:
            return jsonify({
                "code": 500,
                "msg": f"è¯·æ±‚æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}",
                "data": None
            }), 500
            
    except Exception as e:
        print(f"Get Google file public URL failed: {e}")
        return jsonify({
            "code": 500,
            "msg": f"å¤„ç†å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route("/getAccounts", methods=['GET'])
def getAccounts():
    """å¿«é€Ÿè·å–æ‰€æœ‰è´¦å·ä¿¡æ¯ï¼Œä¸è¿›è¡ŒcookieéªŒè¯"""
    try:
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            cursor.execute('''
            SELECT * FROM user_info''')
            rows = cursor.fetchall()
            rows_list = [list(row) for row in rows]

            print("\nğŸ“‹ å½“å‰æ•°æ®è¡¨å†…å®¹ï¼ˆå¿«é€Ÿè·å–ï¼‰ï¼š")
            for row in rows:
                print(row)

            return jsonify(
                {
                    "code": 200,
                    "msg": None,
                    "data": rows_list
                }), 200
    except Exception as e:
        print(f"è·å–è´¦å·åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "code": 500,
            "msg": f"è·å–è´¦å·åˆ—è¡¨å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route("/getValidAccounts",methods=['GET'])
def getValidAccounts():
    """è·å–æœ‰æ•ˆè´¦å·åˆ—è¡¨ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œé¿å…Flask asyncé—®é¢˜ï¼‰"""
    try:
        async def async_get_valid_accounts():
            with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                SELECT * FROM user_info''')
                rows = cursor.fetchall()
                rows_list = [list(row) for row in rows]
                print("\nğŸ“‹ å½“å‰æ•°æ®è¡¨å†…å®¹ï¼š")
                for row in rows:
                    print(row)
                
                # âš¡ ä¼˜åŒ–ï¼šå¹¶å‘éªŒè¯æ‰€æœ‰è´¦å·ï¼Œå¤§å¹…æå‡é€Ÿåº¦
                if rows_list:
                    print(f"\nğŸš€ å¼€å§‹å¹¶å‘éªŒè¯ {len(rows_list)} ä¸ªè´¦å·...")
                    start_time = time.time()
                    
                    # åˆ›å»ºæ‰€æœ‰éªŒè¯ä»»åŠ¡
                    check_tasks = [check_cookie(row[1], row[2]) for row in rows_list]
                    
                    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰éªŒè¯ä»»åŠ¡
                    check_results = await asyncio.gather(*check_tasks, return_exceptions=True)
                    
                    # æ‰¹é‡æ›´æ–°çŠ¶æ€
                    for i, (row, result) in enumerate(zip(rows_list, check_results)):
                        # å¤„ç†å¼‚å¸¸æƒ…å†µ
                        if isinstance(result, Exception):
                            print(f"âš ï¸ è´¦å· {row[1]} éªŒè¯å¼‚å¸¸: {result}")
                            flag = False
                        else:
                            flag = result
                        
                        if not flag:
                            row[4] = 0
                            cursor.execute('''
                            UPDATE user_info 
                            SET status = ? 
                            WHERE id = ?
                            ''', (0, row[0]))
                        else:
                            row[4] = 1
                            cursor.execute('''
                            UPDATE user_info 
                            SET status = ? 
                            WHERE id = ?
                            ''', (1, row[0]))
                    
                    conn.commit()
                    
                    elapsed_time = time.time() - start_time
                    print(f"âœ… å¹¶å‘éªŒè¯å®Œæˆï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’")
                    valid_count = sum(1 for r in check_results if not isinstance(r, Exception) and r)
                    print(f"ğŸ“Š éªŒè¯ç»“æœï¼š{valid_count} ä¸ªæœ‰æ•ˆï¼Œ{len(check_results) - valid_count} ä¸ªæ— æ•ˆ")
                
                # é‡æ–°æŸ¥è¯¢æ›´æ–°åçš„æ•°æ®
                cursor.execute('SELECT * FROM user_info')
                updated_rows = cursor.fetchall()
                updated_rows_list = [list(row) for row in updated_rows]
                
                for row in updated_rows:
                    print(row)
                    
                return updated_rows_list
        
        # åœ¨åŒæ­¥å‡½æ•°ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
        result = asyncio.run(async_get_valid_accounts())
        return jsonify({
            "code": 200,
            "msg": None,
            "data": result
        }), 200
    
    except Exception as e:
        print(f"âŒ è·å–æœ‰æ•ˆè´¦å·å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"è·å–æœ‰æ•ˆè´¦å·å¤±è´¥: {str(e)}",
            "data": None
        }), 500

PRODUCTION_ARTICLE_TABLE_SQL = '''
    CREATE TABLE IF NOT EXISTS production_articles (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        title TEXT,
        content TEXT,
        desc TEXT,
        url TEXT,
        html TEXT,
        publish_status TEXT DEFAULT 'pending',
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
'''

PRODUCTION_IMAGE_TEXT_TABLE_SQL = '''
    CREATE TABLE IF NOT EXISTS production_image_text (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        title TEXT NOT NULL,
        content TEXT NOT NULL,
        media_ids TEXT NOT NULL,
        height INTEGER,
        width INTEGER,
        publish_status TEXT DEFAULT 'pending',
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
'''

PRODUCTION_VIDEO_TABLE_SQL = '''
    CREATE TABLE IF NOT EXISTS production_video (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        title TEXT NOT NULL,
        "desc" TEXT,
        keywords TEXT,
        video TEXT NOT NULL,
        publish_status TEXT DEFAULT 'pending',
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
'''


def ensure_production_article_table(cursor: sqlite3.Cursor):
    """ç¡®ä¿æ–‡ç« åˆ¶ä½œç»“æœè¡¨å­˜åœ¨"""
    # å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='production_articles'")
    table_exists = cursor.fetchone() is not None
    
    if not table_exists:
        # è¡¨ä¸å­˜åœ¨ï¼Œç›´æ¥åˆ›å»ºæ–°è¡¨
        cursor.execute(PRODUCTION_ARTICLE_TABLE_SQL)
    else:
        # è¡¨å·²å­˜åœ¨ï¼Œæ£€æŸ¥å¹¶æ·»åŠ æ–°å­—æ®µ
        # æ£€æŸ¥å¹¶æ·»åŠ  publish_status å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        try:
            cursor.execute("SELECT publish_status FROM production_articles LIMIT 1")
        except sqlite3.OperationalError:
            cursor.execute("ALTER TABLE production_articles ADD COLUMN publish_status TEXT DEFAULT 'pending'")
        
        # æ£€æŸ¥å¹¶æ·»åŠ æ–°å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        new_fields = {
            'title': 'TEXT',
            'content': 'TEXT',
            'desc': 'TEXT',
            'url': 'TEXT',
            'html': 'TEXT'
        }
        for field_name, field_type in new_fields.items():
            try:
                cursor.execute(f"SELECT {field_name} FROM production_articles LIMIT 1")
            except sqlite3.OperationalError:
                # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å­—æ®µ
                cursor.execute(f"ALTER TABLE production_articles ADD COLUMN {field_name} {field_type}")
        
        # å…¼å®¹æ—§å­—æ®µï¼šå¦‚æœæ–°å­—æ®µä¸ºç©ºï¼Œå°è¯•ä»æ—§å­—æ®µè¿ç§»æ•°æ®
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ—§å­—æ®µ
            cursor.execute("PRAGMA table_info(production_articles)")
            columns = [row[1] for row in cursor.fetchall()]
            has_old_fields = 'article_title' in columns
            
            if has_old_fields:
                # è¿ç§»æ—§æ•°æ®åˆ°æ–°å­—æ®µ
                cursor.execute('''
                    UPDATE production_articles 
                    SET title = COALESCE(NULLIF(title, ''), article_title, ''),
                        content = COALESCE(NULLIF(content, ''), article_content, ''),
                        desc = COALESCE(NULLIF(desc, ''), article_desc, ''),
                        url = COALESCE(NULLIF(url, ''), article_media_url, '')
                    WHERE (title IS NULL OR title = '') AND article_title IS NOT NULL
                ''')
        except sqlite3.OperationalError as e:
            # æ—§å­—æ®µä¸å­˜åœ¨æˆ–è¿ç§»å¤±è´¥ï¼Œè·³è¿‡
            print(f"æ•°æ®è¿ç§»è·³è¿‡: {e}")
            pass


def ensure_production_image_text_table(cursor: sqlite3.Cursor):
    """ç¡®ä¿å›¾æ–‡åˆ¶ä½œç»“æœè¡¨å­˜åœ¨"""
    cursor.execute(PRODUCTION_IMAGE_TEXT_TABLE_SQL)
    # æ£€æŸ¥å¹¶æ·»åŠ  publish_status å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    try:
        cursor.execute("SELECT publish_status FROM production_image_text LIMIT 1")
    except sqlite3.OperationalError:
        # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å­—æ®µ
        cursor.execute("ALTER TABLE production_image_text ADD COLUMN publish_status TEXT DEFAULT 'pending'")
    # æ£€æŸ¥å¹¶æ·»åŠ  url å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    try:
        cursor.execute("SELECT url FROM production_image_text LIMIT 1")
    except sqlite3.OperationalError:
        # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å­—æ®µ
        cursor.execute("ALTER TABLE production_image_text ADD COLUMN url TEXT")


def ensure_production_video_table(cursor: sqlite3.Cursor):
    """ç¡®ä¿è§†é¢‘åˆ¶ä½œç»“æœè¡¨å­˜åœ¨"""
    cursor.execute(PRODUCTION_VIDEO_TABLE_SQL)
    # æ£€æŸ¥å¹¶æ·»åŠ  publish_status å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    try:
        cursor.execute("SELECT publish_status FROM production_video LIMIT 1")
    except sqlite3.OperationalError:
        # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å­—æ®µ
        cursor.execute("ALTER TABLE production_video ADD COLUMN publish_status TEXT DEFAULT 'pending'")
    # æ£€æŸ¥å¹¶æ·»åŠ  material_url å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    try:
        cursor.execute("SELECT material_url FROM production_video LIMIT 1")
    except sqlite3.OperationalError:
        # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å­—æ®µ
        cursor.execute("ALTER TABLE production_video ADD COLUMN material_url TEXT")
    # æ£€æŸ¥å¹¶æ·»åŠ  content å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼Œç”¨äºå­˜å‚¨è§†é¢‘å†…å®¹/æ–‡æ¡ˆï¼‰
    try:
        cursor.execute("SELECT content FROM production_video LIMIT 1")
    except sqlite3.OperationalError:
        # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å­—æ®µ
        cursor.execute("ALTER TABLE production_video ADD COLUMN content TEXT")


@app.route('/production/articles', methods=['POST'])
def save_production_article():
    """æ¥æ”¶åˆ¶ä½œä¸­å¿ƒç”Ÿæˆçš„æ–‡ç« å†…å®¹
    å…¥å‚ï¼štitle, content, desc, url, html
    """
    data = request.get_json(silent=True) or {}

    required_fields = ['title', 'content']
    missing_fields = [field for field in required_fields if not data.get(field)]
    if missing_fields:
        return jsonify({
            "code": 400,
            "msg": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}",
            "data": None
        }), 400

    try:
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            
            # æ£€æŸ¥è¡¨ç»“æ„
            cursor.execute("PRAGMA table_info(production_articles)")
            columns = [row[1] for row in cursor.fetchall()]
            has_new_fields = 'title' in columns and 'content' in columns
            has_old_fields = 'article_title' in columns and 'article_content' in columns
            
            title = data.get('title', '').strip()
            content = data.get('content', '').strip()
            desc = data.get('desc', '').strip()
            url = data.get('url', '').strip()
            html = data.get('html', '').strip()
            
            # è·å–ä¸­å›½æ—¶åŒºæ—¶é—´
            china_time = get_china_time()
            
            if has_new_fields and has_old_fields:
                # åŒæ—¶æ›´æ–°æ–°æ—§å­—æ®µï¼ˆå…¼å®¹ï¼‰
                try:
                    cursor.execute('''
                        INSERT INTO production_articles (
                            title,
                            content,
                            desc,
                            url,
                            html,
                            article_title,
                            article_content,
                            article_desc,
                            article_media_url,
                            created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        title, content, desc, url, html,
                        title, content, desc, url,  # æ—§å­—æ®µä¹Ÿå¡«å……ç›¸åŒå€¼
                        china_time
                    ))
                except sqlite3.OperationalError as e:
                    # å¦‚æœæ—§å­—æ®µä¸å­˜åœ¨ï¼Œå›é€€åˆ°åªä½¿ç”¨æ–°å­—æ®µ
                    print(f"å°è¯•æ’å…¥æ–°æ—§å­—æ®µå¤±è´¥ï¼ˆå¯èƒ½æ—§å­—æ®µä¸å­˜åœ¨ï¼‰ï¼Œå›é€€åˆ°åªä½¿ç”¨æ–°å­—æ®µ: {e}")
                    cursor.execute('''
                        INSERT INTO production_articles (
                            title,
                            content,
                            desc,
                            url,
                            html,
                            created_at
                        ) VALUES (?, ?, ?, ?, ?, ?)
                    ''', (title, content, desc, url, html, china_time))
            elif has_new_fields:
                # åªä½¿ç”¨æ–°å­—æ®µ
                print(f"[save_production_article] ä½¿ç”¨æ–°å­—æ®µæ’å…¥ï¼Œæ•°æ®: title={title[:50] if title else 'None'}, contenté•¿åº¦={len(content) if content else 0}, desc={desc[:50] if desc else 'None'}")
                cursor.execute('''
                    INSERT INTO production_articles (
                        title,
                        content,
                        desc,
                        url,
                        html,
                        created_at
                    ) VALUES (?, ?, ?, ?, ?, ?)
                ''', (title, content, desc, url, html, china_time))
                print(f"[save_production_article] æ’å…¥è¯­å¥æ‰§è¡ŒæˆåŠŸ")
            else:
                # åªä½¿ç”¨æ—§å­—æ®µï¼ˆå…¼å®¹ï¼‰
                print(f"[save_production_article] ä½¿ç”¨æ—§å­—æ®µæ’å…¥")
                cursor.execute('''
                    INSERT INTO production_articles (
                        article_title,
                        article_content,
                        article_desc,
                        article_media_url,
                        created_at
                    ) VALUES (?, ?, ?, ?, ?)
                ''', (title, content, desc, url, china_time))
            
            conn.commit()
            record_id = cursor.lastrowid
            print(f"[save_production_article] æäº¤æˆåŠŸï¼Œè®°å½•ID: {record_id}")
            
            # éªŒè¯æ’å…¥æ˜¯å¦æˆåŠŸ
            cursor.execute('SELECT id, title FROM production_articles WHERE id = ?', (record_id,))
            verify_row = cursor.fetchone()
            if verify_row:
                print(f"[save_production_article] âœ… éªŒè¯æˆåŠŸï¼Œæ‰¾åˆ°è®°å½•: ID={verify_row[0]}, title={verify_row[1][:50] if verify_row[1] else 'None'}")
            else:
                print(f"[save_production_article] âš ï¸ è­¦å‘Šï¼šæ’å…¥åéªŒè¯å¤±è´¥ï¼Œæœªæ‰¾åˆ°è®°å½•ID={record_id}")

        return jsonify({
            "code": 200,
            "msg": "æ–‡ç« åˆ¶ä½œç»“æœå·²ä¿å­˜",
            "data": {
                "id": record_id
            }
        }), 200

    except Exception as e:
        print(f"ä¿å­˜æ–‡ç« åˆ¶ä½œç»“æœå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"ä¿å­˜å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/production/video', methods=['POST'])
def save_production_video():
    """
    æ–°å¢è§†é¢‘ä¿¡æ¯æ¥å£
    å‚æ•°: title, desc, keywords, video
    """
    data = request.get_json(silent=True) or {}
    
    # éªŒè¯å¿…å¡«å­—æ®µ
    required_fields = ['title', 'video']
    missing_fields = [field for field in required_fields if not data.get(field)]
    if missing_fields:
        return jsonify({
            "code": 400,
            "msg": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}",
            "data": None
        }), 400
    
    try:
        import json
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_video_table(cursor)
            
            # å¤„ç† keywordsï¼šå¦‚æœæ˜¯æ•°ç»„ï¼Œè½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ï¼›å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
            keywords = data.get('keywords', '')
            if isinstance(keywords, list):
                keywords = json.dumps(keywords, ensure_ascii=False)
            elif keywords:
                keywords = str(keywords).strip()
            else:
                keywords = None
            
            # è·å–ä¸­å›½æ—¶åŒºæ—¶é—´
            china_time = get_china_time()
            
            cursor.execute('''
                INSERT INTO production_video (
                    title,
                    "desc",
                    keywords,
                    video,
                    material_url,
                    created_at
                ) VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                data.get('title', '').strip(),
                data.get('desc', '').strip() if data.get('desc') else None,
                keywords,
                data.get('video', '').strip(),
                data.get('material_url', '').strip() if data.get('material_url') else None,
                china_time
            ))
            conn.commit()
            record_id = cursor.lastrowid
        
        return jsonify({
            "code": 200,
            "msg": "è§†é¢‘ä¿¡æ¯å·²ä¿å­˜",
            "data": {
                "id": record_id
            }
        }), 200
    
    except Exception as e:
        print(f"ä¿å­˜è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({
            "code": 500,
            "msg": f"ä¿å­˜å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/production/video-from-n8n', methods=['POST'])
def save_production_video_from_n8n():
    """
    ä»n8nè°ƒç”¨ï¼Œä¿å­˜ç”Ÿæˆçš„è§†é¢‘åˆ°åˆ¶ä½œä¸­å¿ƒåˆ—è¡¨
    å‚æ•°: title, content, desc, material_url (åŸå§‹ç´ æURL), url (ç”Ÿæˆç´ æURL)
    åŒæ—¶å°†ç”Ÿæˆçš„è§†é¢‘ä¿å­˜åˆ°ç´ æåº“ï¼Œæ ‡è®°ä¸º"ç”Ÿæˆç´ æ"
    """
    data = request.get_json(silent=True) or {}
    
    # éªŒè¯å¿…å¡«å­—æ®µ
    required_fields = ['title', 'url']
    missing_fields = [field for field in required_fields if not data.get(field)]
    if missing_fields:
        return jsonify({
            "code": 400,
            "msg": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}",
            "data": None
        }), 400
    
    try:
        import uuid
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_video_table(cursor)
            
            # ä¿å­˜åˆ°åˆ¶ä½œä¸­å¿ƒ
            material_url = data.get('material_url', '').strip() if data.get('material_url') else None
            generated_url = data.get('url', '').strip()  # ç”Ÿæˆç´ æURL
            
            # è·å–ä¸­å›½æ—¶åŒºæ—¶é—´
            china_time = get_china_time()
            
            cursor.execute('''
                INSERT INTO production_video (
                    title,
                    content,
                    "desc",
                    video,
                    material_url,
                    created_at
                ) VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                data.get('title', '').strip(),
                data.get('content', '').strip() if data.get('content') else None,
                data.get('desc', '').strip() if data.get('desc') else None,
                generated_url,  # url å¯¹åº” video å­—æ®µï¼ˆç”Ÿæˆå†…å®¹é“¾æ¥ï¼‰
                material_url,  # åŸå§‹ç´ æURL
                china_time
            ))
            conn.commit()
            record_id = cursor.lastrowid
            
            # å°†ç”Ÿæˆçš„è§†é¢‘ä¿å­˜åˆ°ç´ æåº“ï¼ˆfile_recordsè¡¨ï¼‰
            # ç¡®ä¿è¡¨ä¸­æœ‰ source å’Œ uri å­—æ®µ
            try:
                cursor.execute("SELECT source FROM file_records LIMIT 1")
            except sqlite3.OperationalError:
                cursor.execute("ALTER TABLE file_records ADD COLUMN source TEXT DEFAULT 'æœ¬åœ°ä¸Šä¼ '")
            try:
                cursor.execute("SELECT uri FROM file_records LIMIT 1")
            except sqlite3.OperationalError:
                cursor.execute("ALTER TABLE file_records ADD COLUMN uri TEXT")
            
            # ä»URLä¸­æå–æ–‡ä»¶å
            url_parts = generated_url.split('/')
            filename = url_parts[-1] if url_parts else f"generated_video_{record_id}.mp4"
            # å¦‚æœæ–‡ä»¶ååŒ…å«æŸ¥è¯¢å‚æ•°ï¼Œå»æ‰
            if '?' in filename:
                filename = filename.split('?')[0]
            
            # ç”ŸæˆUUIDå’Œfile_path
            uuid_v1 = uuid.uuid1()
            file_path = f"{uuid_v1}_{filename}"
            
            # æ’å…¥åˆ°ç´ æåº“ï¼Œæ ‡è®°ä¸º"ç”Ÿæˆç´ æ"
            cursor.execute('''
                INSERT INTO file_records (filename, filesize, file_path, source, uri)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                filename,
                0,  # ç”Ÿæˆç´ æå¤§å°æœªçŸ¥ï¼Œè®¾ä¸º0
                file_path,
                'ç”Ÿæˆç´ æ',  # æ ‡è®°ä¸ºç”Ÿæˆç´ æ
                generated_url  # ä¿å­˜å®Œæ•´URLåˆ°uriå­—æ®µ
            ))
            conn.commit()
            print(f"âœ… ç”Ÿæˆç´ æå·²ä¿å­˜åˆ°ç´ æåº“: {filename}")
        
        return jsonify({
            "code": 200,
            "msg": "è§†é¢‘ä¿¡æ¯å·²ä¿å­˜",
            "data": {
                "id": record_id
            }
        }), 200
    
    except Exception as e:
        print(f"ä¿å­˜è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"ä¿å­˜å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/production/image-text', methods=['POST'])
def save_production_image_text():
    """
    æ–°å¢å›¾æ–‡ä¿¡æ¯æ¥å£
    å‚æ•°: title, content, urls (URLæ•°ç»„)
    """
    import json as json_module  # å¯¼å…¥jsonæ¨¡å—ç”¨äºæ—¥å¿—
    data = request.get_json(silent=True) or {}
    
    # ğŸ“ è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æ¥æ”¶åˆ°çš„å®Œæ•´æ•°æ®
    print(f"\n[å›¾æ–‡ä¿å­˜] æ”¶åˆ°è¯·æ±‚ï¼Œå®Œæ•´æ•°æ®: {json_module.dumps(data, ensure_ascii=False, indent=2)}")
    print(f"[å›¾æ–‡ä¿å­˜] urlså­—æ®µç±»å‹: {type(data.get('urls'))}")
    print(f"[å›¾æ–‡ä¿å­˜] urlså­—æ®µå€¼: {data.get('urls')}")
    if isinstance(data.get('urls'), list):
        print(f"[å›¾æ–‡ä¿å­˜] urlsæ•°ç»„é•¿åº¦: {len(data.get('urls'))}")
        print(f"[å›¾æ–‡ä¿å­˜] urlsæ•°ç»„å†…å®¹: {data.get('urls')}")
    
    # âš ï¸ é‡è¦ï¼šæ£€æŸ¥æ˜¯å¦é”™è¯¯ä½¿ç”¨äº† media_ids å­—æ®µï¼ˆé˜²æ­¢é‡å¤å‡ºç°çš„é—®é¢˜ï¼‰
    if 'media_ids' in data and 'urls' not in data:
        return jsonify({
            "code": 400,
            "msg": "é”™è¯¯ï¼šè¯·ä½¿ç”¨ 'urls' å­—æ®µè€Œä¸æ˜¯ 'media_ids' å­—æ®µã€‚æ¥å£æœŸæœ›å‚æ•°ï¼štitle, content, urls (URLæ•°ç»„)",
            "data": None
        }), 400
    
    # éªŒè¯å¿…å¡«å­—æ®µ
    required_fields = ['title', 'content', 'urls']
    missing_fields = [field for field in required_fields if not data.get(field)]
    if missing_fields:
        return jsonify({
            "code": 400,
            "msg": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}ã€‚æ³¨æ„ï¼šè¯·ä½¿ç”¨ 'urls' å­—æ®µï¼ˆæ•°ç»„ï¼‰ï¼Œä¸æ˜¯ 'media_ids'",
            "data": None
        }), 400
    
    # éªŒè¯ urls æ˜¯å¦ä¸ºæ•°ç»„
    urls = data.get('urls', [])
    if not isinstance(urls, list):
        return jsonify({
            "code": 400,
            "msg": "urls å¿…é¡»æ˜¯æ•°ç»„",
            "data": None
        }), 400
    
    # è¿‡æ»¤ç©ºå€¼
    urls = [url.strip() for url in urls if url and url.strip()]
    if not urls:
        return jsonify({
            "code": 400,
            "msg": "urls æ•°ç»„ä¸èƒ½ä¸ºç©º",
            "data": None
        }), 400
    
    try:
        import json
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_image_text_table(cursor)
            
            # å°† urls æ•°ç»„è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²å­˜å‚¨åˆ° media_ids å­—æ®µï¼ˆä¿æŒæ•°æ®åº“å…¼å®¹ï¼‰
            media_ids_json = json.dumps(urls, ensure_ascii=False)
            print(f"[å›¾æ–‡ä¿å­˜] è½¬æ¢åçš„JSONå­—ç¬¦ä¸²: {media_ids_json}")
            print(f"[å›¾æ–‡ä¿å­˜] JSONå­—ç¬¦ä¸²é•¿åº¦: {len(media_ids_json)}")
            
            # å°†ç¬¬ä¸€ä¸ª URL å­˜å‚¨åˆ° url å­—æ®µï¼ˆç”¨äºå¿«é€Ÿè®¿é—®ï¼‰
            first_url = urls[0] if urls else None
            print(f"[å›¾æ–‡ä¿å­˜] ç¬¬ä¸€ä¸ªURL: {first_url}")
            
            # è·å–ä¸­å›½æ—¶åŒºæ—¶é—´
            china_time = get_china_time()
            
            cursor.execute('''
                INSERT INTO production_image_text (
                    title,
                    content,
                    media_ids,
                    url,
                    created_at
                ) VALUES (?, ?, ?, ?, ?)
            ''', (
                data.get('title', '').strip(),
                data.get('content', '').strip(),
                media_ids_json,
                first_url,
                china_time
            ))
            conn.commit()
            record_id = cursor.lastrowid
            print(f"[å›¾æ–‡ä¿å­˜] âœ… ä¿å­˜æˆåŠŸï¼Œè®°å½•ID: {record_id}")
            print(f"[å›¾æ–‡ä¿å­˜] ä¿å­˜çš„urlsæ•°é‡: {len(urls)}")
        
        return jsonify({
            "code": 200,
            "msg": "å›¾æ–‡ä¿¡æ¯å·²ä¿å­˜",
            "data": {
                "id": record_id
            }
        }), 200
    
    except Exception as e:
        print(f"ä¿å­˜å›¾æ–‡ä¿¡æ¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"ä¿å­˜å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/production/records', methods=['GET'])
def list_production_records():
    """
    è·å–åˆ¶ä½œä¸­å¿ƒäº§å‡ºçš„ç»Ÿä¸€åˆ—è¡¨ï¼Œå¯æŒ‰ content_type è¿‡æ»¤
    æ”¯æŒ articleã€image-text å’Œ video ç±»å‹
    æ³¨æ„ï¼šå·²æˆåŠŸå‘å¸ƒçš„è®°å½•ï¼ˆpublish_status = 'success'ï¼‰ä¸ä¼šå‡ºç°åœ¨åˆ¶ä½œä¸­å¿ƒåˆ—è¡¨ä¸­ï¼Œ
    å®ƒä»¬åªä¼šåœ¨å‘å¸ƒä¸­å¿ƒåˆ—è¡¨ä¸­æ˜¾ç¤º
    """
    content_type = (request.args.get('content_type') or '').strip().lower()
    supported_types = {'', 'all', 'article', 'image-text', 'video'}

    if content_type and content_type not in supported_types:
        # ä¸æ”¯æŒçš„ç±»å‹ç›´æ¥è¿”å›ç©ºæ•°ç»„ï¼Œæ–¹ä¾¿å‰ç«¯å…¼å®¹
        return jsonify({
            "code": 200,
            "msg": "success",
            "data": {
                "items": [],
                "total": 0
            }
        }), 200

    records = []

    try:
        import json
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            ensure_production_image_text_table(cursor)
            ensure_production_video_table(cursor)

            # è·å–æ–‡ç« è®°å½•
            if not content_type or content_type in ('all', 'article'):
                # æ£€æŸ¥è¡¨ç»“æ„ï¼Œä¼˜å…ˆä½¿ç”¨æ–°å­—æ®µ
                cursor.execute("PRAGMA table_info(production_articles)")
                columns = [row[1] for row in cursor.fetchall()]
                has_new_fields = 'title' in columns and 'content' in columns
                has_old_fields = 'article_title' in columns and 'article_content' in columns
                
                if has_new_fields and has_old_fields:
                    # åŒæ—¶æœ‰æ–°å­—æ®µå’Œæ—§å­—æ®µï¼Œä½¿ç”¨ COALESCE å…¼å®¹
                    cursor.execute('''
                        SELECT id,
                               COALESCE(NULLIF(title, ''), article_title, '') as title,
                               COALESCE(NULLIF(content, ''), article_content, '') as content,
                               COALESCE(NULLIF(desc, ''), article_desc, '') as desc,
                               COALESCE(NULLIF(url, ''), article_media_url, '') as url,
                               COALESCE(html, '') as html,
                               COALESCE(publish_status, 'pending') as publish_status,
                               created_at
                        FROM production_articles
                        WHERE COALESCE(publish_status, 'pending') != 'success'
                        ORDER BY created_at DESC, id DESC
                    ''')
                elif has_new_fields:
                    # åªæœ‰æ–°å­—æ®µ
                    cursor.execute('''
                        SELECT id,
                               title,
                               content,
                               desc,
                               url,
                               COALESCE(html, '') as html,
                               COALESCE(publish_status, 'pending') as publish_status,
                               created_at
                        FROM production_articles
                        WHERE COALESCE(publish_status, 'pending') != 'success'
                        ORDER BY created_at DESC, id DESC
                    ''')
                else:
                    # åªæœ‰æ—§å­—æ®µï¼ˆå…¼å®¹ï¼‰
                    cursor.execute('''
                        SELECT id,
                               article_title as title,
                               article_content as content,
                               article_desc as desc,
                               article_media_url as url,
                               '' as html,
                               COALESCE(publish_status, 'pending') as publish_status,
                               created_at
                        FROM production_articles
                        WHERE COALESCE(publish_status, 'pending') != 'success'
                        ORDER BY created_at DESC, id DESC
                    ''')
                
                article_rows = cursor.fetchall()

                for row in article_rows:
                    records.append({
                        "id": row["id"],
                        "content_type": "article",
                        "title": row["title"] or "",
                        "content": row["content"] or "",
                        "desc": row["desc"] or "",
                        "url": row["url"] or "",
                        "html": row["html"] or "",
                        "summary": row["desc"] or "",  # å…¼å®¹å­—æ®µ
                        "publish_status": row["publish_status"] or "pending",
                        "created_at": row["created_at"]
                    })

            # è·å–å›¾æ–‡è®°å½•
            if not content_type or content_type in ('all', 'image-text'):
                cursor.execute('''
                    SELECT id,
                           title,
                           content,
                           media_ids,
                           height,
                           width,
                           url,
                           COALESCE(publish_status, 'pending') as publish_status,
                           created_at
                    FROM production_image_text
                    WHERE COALESCE(publish_status, 'pending') != 'success'
                    ORDER BY created_at DESC, id DESC
                ''')
                image_text_rows = cursor.fetchall()

                for row in image_text_rows:
                    # è§£æ media_ids JSON å­—ç¬¦ä¸²ä¸ºæ•°ç»„
                    try:
                        media_ids = json.loads(row["media_ids"]) if row["media_ids"] else []
                    except:
                        media_ids = []
                    
                    records.append({
                        "id": row["id"],
                        "content_type": "image-text",
                        "title": row["title"],
                        "summary": "",  # å›¾æ–‡ç±»å‹æ²¡æœ‰æ‘˜è¦å­—æ®µ
                        "content": row["content"],
                        "media_ids": media_ids,
                        "height": row["height"],
                        "width": row["width"],
                        "url": row["url"],  # æ·»åŠ  url å­—æ®µ
                        "publish_status": row["publish_status"] or "pending",  # å‘å¸ƒçŠ¶æ€
                        "created_at": row["created_at"]
                    })

            # è·å–è§†é¢‘è®°å½•
            if not content_type or content_type in ('all', 'video'):
                cursor.execute('''
                    SELECT id,
                           title,
                           content,
                           "desc",
                           keywords,
                           video,
                           material_url,
                           COALESCE(publish_status, 'pending') as publish_status,
                           created_at
                    FROM production_video
                    WHERE COALESCE(publish_status, 'pending') != 'success'
                    ORDER BY created_at DESC, id DESC
                ''')
                video_rows = cursor.fetchall()

                for row in video_rows:
                    # è§£æ keywords JSON å­—ç¬¦ä¸²ä¸ºæ•°ç»„ï¼ˆå¦‚æœæ˜¯JSONæ ¼å¼ï¼‰
                    keywords = row["keywords"] or ""
                    try:
                        keywords_list = json.loads(keywords) if keywords else []
                    except:
                        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•æŒ‰é€—å·åˆ†å‰²
                        keywords_list = [k.strip() for k in keywords.split(',')] if keywords else []
                    
                    records.append({
                        "id": row["id"],
                        "content_type": "video",
                        "title": row["title"],
                        "summary": row["desc"] or "",  # ä½¿ç”¨ desc ä½œä¸ºæ‘˜è¦
                        "content": row["content"] or "",  # è§†é¢‘å†…å®¹/æ–‡æ¡ˆ
                        "keywords": keywords_list,  # å…³é”®è¯åˆ—è¡¨
                        "video": row["video"],  # è§†é¢‘URLæˆ–è·¯å¾„ï¼ˆç”Ÿæˆå†…å®¹é“¾æ¥ï¼‰
                        "material_url": row["material_url"] or "",  # ç´ æç½‘å€
                        "publish_status": row["publish_status"] or "pending",  # å‘å¸ƒçŠ¶æ€
                        "created_at": row["created_at"]
                    })

    except Exception as e:
        print(f"è·å–åˆ¶ä½œè®°å½•å¤±è´¥: {e}")
        return jsonify({
            "code": 500,
            "msg": f"è·å–åˆ¶ä½œè®°å½•å¤±è´¥: {str(e)}",
            "data": None
        }), 500

    # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    # å¦‚æœ created_at ä¸ºç©ºï¼Œåˆ™æŒ‰ id å€’åº
    records.sort(key=lambda x: (x.get('created_at') or '', x.get('id', 0)), reverse=True)
    
    # å¯æŒ‰ content_type è¿‡æ»¤
    if content_type and content_type not in ('all', ''):
        filtered = [record for record in records if record["content_type"] == content_type]
    else:
        filtered = records

    return jsonify({
        "code": 200,
        "msg": "success",
        "data": {
            "items": filtered,
            "total": len(filtered)
        }
    }), 200


# å…¬ä¼—å·ç›‘æµ‹å·ä¸»è¡¨SQL
WECHAT_MONITOR_ACCOUNTS_TABLE_SQL = '''
    CREATE TABLE IF NOT EXISTS wechat_monitor_accounts (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        media_id TEXT NOT NULL UNIQUE,
        account_name TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
'''

# å…¬ä¼—å·çˆ¬å–æ–‡ç« è¡¨SQL
WECHAT_HOTSPOT_ARTICLES_TABLE_SQL = '''
    CREATE TABLE IF NOT EXISTS wechat_hotspot_articles (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        nick_name TEXT,
        biz TEXT,
        create_time TEXT,
        title TEXT,
        url TEXT UNIQUE,
        content TEXT,
        content_multi_text TEXT,
        pubtime TEXT,
        read_count INTEGER DEFAULT 0,
        zan INTEGER DEFAULT 0,
        looking INTEGER DEFAULT 0,
        share_num INTEGER DEFAULT 0,
        collect_num INTEGER DEFAULT 0,
        comment_count INTEGER DEFAULT 0,
        summary TEXT,
        headline TEXT,
        keywords TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
'''

def ensure_wechat_monitor_accounts_table(cursor: sqlite3.Cursor):
    """ç¡®ä¿å…¬ä¼—å·ç›‘æµ‹å·ä¸»è¡¨å­˜åœ¨"""
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='wechat_monitor_accounts'")
    table_exists = cursor.fetchone() is not None
    
    if not table_exists:
        cursor.execute(WECHAT_MONITOR_ACCOUNTS_TABLE_SQL)

def ensure_wechat_hotspot_articles_table(cursor: sqlite3.Cursor):
    """ç¡®ä¿å…¬ä¼—å·çˆ¬å–æ–‡ç« è¡¨å­˜åœ¨"""
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='wechat_hotspot_articles'")
    table_exists = cursor.fetchone() is not None
    
    if not table_exists:
        cursor.execute(WECHAT_HOTSPOT_ARTICLES_TABLE_SQL)

@app.route('/hotspot/wechat/accounts', methods=['POST'])
def add_wechat_monitor_account():
    """æ·»åŠ å…¬ä¼—å·ç›‘æµ‹å·ä¸»"""
    data = request.get_json(silent=True) or {}
    
    # æ”¯æŒæ–°å‚æ•° biz å’Œ nameï¼Œä¹Ÿå…¼å®¹æ—§çš„ media_id
    biz = data.get('biz', '').strip() or data.get('media_id', '').strip()
    name = data.get('name', '').strip() or data.get('account_name', '').strip()
    
    if not biz:
        return jsonify({
            "code": 400,
            "msg": "bizä¸èƒ½ä¸ºç©º",
            "data": None
        }), 400
    
    if not name:
        return jsonify({
            "code": 400,
            "msg": "nameä¸èƒ½ä¸ºç©º",
            "data": None
        }), 400
    
    try:
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_wechat_monitor_accounts_table(cursor)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ ¹æ®biz/media_idï¼‰
            cursor.execute('SELECT id, account_name FROM wechat_monitor_accounts WHERE media_id = ?', (biz,))
            existing = cursor.fetchone()
            
            if existing:
                return jsonify({
                    "code": 400,
                    "msg": "è¯¥å·ä¸»å·²å­˜åœ¨",
                    "data": {
                        "id": existing[0],
                        "media_id": biz,
                        "account_name": existing[1]
                    }
                }), 400
            
            # æ’å…¥æ–°è®°å½•
            china_time = get_china_time()
            cursor.execute('''
                INSERT INTO wechat_monitor_accounts (media_id, account_name, created_at, updated_at)
                VALUES (?, ?, ?, ?)
            ''', (biz, name, china_time, china_time))
            
            conn.commit()
            record_id = cursor.lastrowid
            
            return jsonify({
                "code": 200,
                "msg": "æ·»åŠ æˆåŠŸ",
                "data": {
                    "id": record_id,
                    "media_id": biz,
                    "account_name": name
                }
            }), 200
            
    except sqlite3.IntegrityError:
        return jsonify({
            "code": 400,
            "msg": "è¯¥å·ä¸»å·²å­˜åœ¨",
            "data": None
        }), 400
    except Exception as e:
        print(f"æ·»åŠ å…¬ä¼—å·ç›‘æµ‹å·ä¸»å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"æ·»åŠ å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route('/hotspot/wechat/accounts', methods=['GET'])
def list_wechat_monitor_accounts():
    """è·å–å…¬ä¼—å·ç›‘æµ‹å·ä¸»åˆ—è¡¨"""
    try:
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            ensure_wechat_monitor_accounts_table(cursor)
            
            cursor.execute('''
                SELECT id, media_id, account_name, created_at, updated_at
                FROM wechat_monitor_accounts
                ORDER BY created_at DESC
            ''')
            
            rows = cursor.fetchall()
            accounts = []
            for row in rows:
                accounts.append({
                    "id": row["id"],
                    "media_id": row["media_id"],
                    "account_name": row["account_name"],
                    "created_at": row["created_at"],
                    "updated_at": row["updated_at"]
                })
            
            return jsonify({
                "code": 200,
                "msg": "success",
                "data": {
                    "items": accounts,
                    "total": len(accounts)
                }
            }), 200
            
    except Exception as e:
        print(f"è·å–å…¬ä¼—å·ç›‘æµ‹å·ä¸»åˆ—è¡¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"è·å–å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route('/hotspot/wechat/accounts/<int:account_id>', methods=['DELETE'])
def delete_wechat_monitor_account(account_id):
    """åˆ é™¤å…¬ä¼—å·ç›‘æµ‹å·ä¸»"""
    try:
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_wechat_monitor_accounts_table(cursor)
            
            cursor.execute('DELETE FROM wechat_monitor_accounts WHERE id = ?', (account_id,))
            conn.commit()
            
            if cursor.rowcount > 0:
                return jsonify({
                    "code": 200,
                    "msg": "åˆ é™¤æˆåŠŸ",
                    "data": None
                }), 200
            else:
                return jsonify({
                    "code": 404,
                    "msg": "è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
    except Exception as e:
        print(f"åˆ é™¤å…¬ä¼—å·ç›‘æµ‹å·ä¸»å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"åˆ é™¤å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route('/hotspot/wechat/articles', methods=['POST'])
def save_wechat_hotspot_articles():
    """ä¿å­˜å…¬ä¼—å·çˆ¬å–æ–‡ç« åˆ—è¡¨ï¼ˆä»n8nè°ƒç”¨ï¼‰"""
    data = request.get_json(silent=True) or {}
    
    # æ”¯æŒå¤šç§æ•°æ®æ ¼å¼ï¼š
    # 1. rss_list æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
    # 2. articles æ ¼å¼ï¼ˆæ—§æ ¼å¼ï¼‰
    # 3. ç›´æ¥æ˜¯æ•°ç»„
    if 'rss_list' in data:
        # æ–°æ ¼å¼ï¼šä»n8n RSSåˆ—è¡¨ä¼ å…¥
        raw_articles = data.get('rss_list', [])
        articles = []
        
        for item in raw_articles:
            # å¤„ç†æ—¥æœŸæ ¼å¼è½¬æ¢ï¼šISOæ ¼å¼ -> æ•°æ®åº“æ ¼å¼
            pub_date = item.get('pubDate', '') or item.get('isoDate', '')
            pubtime_str = ''
            create_time_str = ''
            
            # å°è¯•è½¬æ¢ISOæ—¥æœŸæ ¼å¼ä¸ºæ•°æ®åº“æ ¼å¼
            try:
                if pub_date:
                    # å¤„ç†ISOæ ¼å¼æ—¥æœŸ: 2025-12-02T07:01:05.000Z
                    if 'T' in pub_date:
                        # æ›¿æ¢Zä¸º+00:00ä»¥ä¾¿parse
                        date_str = pub_date.replace('Z', '+00:00')
                        # å¦‚æœå·²ç»æ˜¯+00:00æ ¼å¼ï¼Œç›´æ¥è§£æ
                        if '+' in date_str or '-' in date_str[-6:]:
                            dt = datetime.fromisoformat(date_str)
                        else:
                            # å°è¯•å…¶ä»–æ ¼å¼
                            dt = datetime.strptime(pub_date, '%Y-%m-%dT%H:%M:%S.%fZ')
                            from datetime import timezone
                            dt = dt.replace(tzinfo=timezone.utc)
                        
                        # è½¬æ¢ä¸ºä¸­å›½æ—¶åŒº
                        from datetime import timezone, timedelta
                        china_tz = timezone(timedelta(hours=8))
                        dt_china = dt.astimezone(china_tz)
                        # æ ¼å¼åŒ–ä¸º: 2025-12-02 15:01:05
                        pubtime_str = dt_china.strftime('%Y-%m-%d %H:%M:%S')
                        create_time_str = pubtime_str
                    else:
                        # å¦‚æœä¸æ˜¯ISOæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                        pubtime_str = pub_date
                        create_time_str = pub_date
            except Exception as e:
                print(f"æ—¥æœŸæ ¼å¼è½¬æ¢å¤±è´¥: {pub_date}, é”™è¯¯: {e}")
                # ä½¿ç”¨åŸå§‹å€¼æˆ–å½“å‰æ—¶é—´
                if pub_date:
                    pubtime_str = pub_date
                    create_time_str = pub_date
                else:
                    pubtime_str = get_china_time()
                    create_time_str = get_china_time()
            
            # è½¬æ¢æ ¼å¼ï¼šä»RSSæ ¼å¼è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼
            article = {
                'title': item.get('title', ''),
                'url': item.get('link', ''),
                'pubtime': pubtime_str,
                'nick_name': item.get('name', ''),
                'content': '',  # RSSåˆ—è¡¨å¯èƒ½æ²¡æœ‰content
                'summary': item.get('title', ''),  # ä½¿ç”¨titleä½œä¸ºsummary
                'biz': '',  # RSSåˆ—è¡¨å¯èƒ½æ²¡æœ‰biz
                'create_time': create_time_str,
                'read_count': 0,
                'zan': 0,
                'looking': 0,
                'share_num': 0,
                'collect_num': 0,
                'comment_count': 0,
            }
            # å¦‚æœæœ‰typeå­—æ®µï¼Œå­˜å‚¨åˆ°keywordsä¸­ï¼ˆä½œä¸ºJSONæ•°ç»„ï¼‰
            account_type = item.get('type', '')
            if account_type:
                # å°†typeä¿¡æ¯å­˜å‚¨åˆ°keywordså­—æ®µï¼ˆä½œä¸ºæ•°ç»„ï¼‰
                article['keywords'] = [account_type]
            articles.append(article)
    elif 'articles' in data:
        # æ—§æ ¼å¼
        articles = data.get('articles', [])
    elif isinstance(data, list):
        # ç›´æ¥æ˜¯æ•°ç»„
        articles = data
    else:
        articles = []
    
    if not isinstance(articles, list) or len(articles) == 0:
        return jsonify({
            "code": 400,
            "msg": "rss_listæˆ–articleså¿…é¡»æ˜¯éç©ºæ•°ç»„",
            "data": None
        }), 400
    
    try:
        import json
        china_time = get_china_time()
        inserted_count = 0
        updated_count = 0
        skipped_count = 0
        errors = []
        
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_wechat_hotspot_articles_table(cursor)
            
            for idx, article in enumerate(articles):
                try:
                    # æå–å­—æ®µ
                    nick_name = article.get('nick_name', '').strip() if article.get('nick_name') else None
                    biz = article.get('biz', '').strip() if article.get('biz') else None
                    create_time = article.get('create_time', '').strip() if article.get('create_time') else None
                    title = article.get('title', '').strip() if article.get('title') else None
                    url = article.get('url', '').strip() if article.get('url') else None
                    content = article.get('content', '').strip() if article.get('content') else None
                    content_multi_text = article.get('content_multi_text', '').strip() if article.get('content_multi_text') else None
                    pubtime = article.get('pubtime', '').strip() if article.get('pubtime') else None
                    read_count = article.get('read', 0) or 0
                    zan = article.get('zan', 0) or 0
                    looking = article.get('looking', 0) or 0
                    share_num = article.get('share_num', 0) or 0
                    collect_num = article.get('collect_num', 0) or 0
                    comment_count = article.get('comment_count', 0) or 0
                    summary = article.get('summary', '').strip() if article.get('summary') else None
                    headline = article.get('headline', '').strip() if article.get('headline') else None
                    
                    # å¤„ç†keywordsï¼šå¦‚æœæ˜¯æ•°ç»„ï¼Œè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                    keywords = article.get('keywords', None)
                    if isinstance(keywords, list):
                        keywords = json.dumps(keywords, ensure_ascii=False)
                    elif keywords:
                        keywords = str(keywords).strip()
                    else:
                        keywords = None
                    
                    # URLæ˜¯å”¯ä¸€æ ‡è¯†ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™æ’å…¥
                    if url:
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        cursor.execute('SELECT id FROM wechat_hotspot_articles WHERE url = ?', (url,))
                        existing = cursor.fetchone()
                        
                        if existing:
                            # æ›´æ–°ç°æœ‰è®°å½•
                            cursor.execute('''
                                UPDATE wechat_hotspot_articles SET
                                    nick_name = ?,
                                    biz = ?,
                                    create_time = ?,
                                    title = ?,
                                    content = ?,
                                    content_multi_text = ?,
                                    pubtime = ?,
                                    read_count = ?,
                                    zan = ?,
                                    looking = ?,
                                    share_num = ?,
                                    collect_num = ?,
                                    comment_count = ?,
                                    summary = ?,
                                    headline = ?,
                                    keywords = ?,
                                    updated_at = ?
                                WHERE url = ?
                            ''', (
                                nick_name, biz, create_time, title, content, content_multi_text,
                                pubtime, read_count, zan, looking, share_num, collect_num,
                                comment_count, summary, headline, keywords, china_time, url
                            ))
                            updated_count += 1
                        else:
                            # æ’å…¥æ–°è®°å½•
                            cursor.execute('''
                                INSERT INTO wechat_hotspot_articles (
                                    nick_name, biz, create_time, title, url, content, content_multi_text,
                                    pubtime, read_count, zan, looking, share_num, collect_num,
                                    comment_count, summary, headline, keywords, created_at, updated_at
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            ''', (
                                nick_name, biz, create_time, title, url, content, content_multi_text,
                                pubtime, read_count, zan, looking, share_num, collect_num,
                                comment_count, summary, headline, keywords, china_time, china_time
                            ))
                            inserted_count += 1
                    else:
                        skipped_count += 1
                        errors.append(f"ç¬¬{idx+1}æ¡è®°å½•ç¼ºå°‘urlå­—æ®µï¼Œå·²è·³è¿‡")
                        
                except Exception as e:
                    skipped_count += 1
                    error_msg = f"ç¬¬{idx+1}æ¡è®°å½•å¤„ç†å¤±è´¥: {str(e)[:100]}"
                    errors.append(error_msg)
                    print(f"å¤„ç†å…¬ä¼—å·æ–‡ç« å¤±è´¥: {error_msg}")
                    continue
            
            conn.commit()
            
            result_msg = f"ä¿å­˜å®Œæˆï¼šæ–°å¢{inserted_count}æ¡ï¼Œæ›´æ–°{updated_count}æ¡"
            if skipped_count > 0:
                result_msg += f"ï¼Œè·³è¿‡{skipped_count}æ¡"
            
            return jsonify({
                "code": 200,
                "msg": result_msg,
                "data": {
                    "inserted": inserted_count,
                    "updated": updated_count,
                    "skipped": skipped_count,
                    "total": len(articles),
                    "errors": errors if errors else None
                }
            }), 200
            
    except Exception as e:
        print(f"ä¿å­˜å…¬ä¼—å·çˆ¬å–æ–‡ç« å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"ä¿å­˜å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route('/hotspot/wechat/articles', methods=['GET'])
def list_wechat_hotspot_articles():
    """è·å–å…¬ä¼—å·çˆ¬å–æ–‡ç« åˆ—è¡¨"""
    try:
        import json
        from datetime import datetime, timedelta
        
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            ensure_wechat_hotspot_articles_table(cursor)
            
            # è·å–æŸ¥è¯¢å‚æ•°
            page = int(request.args.get('page', 1))
            page_size = int(request.args.get('page_size', 20))
            offset = (page - 1) * page_size
            
            # è·å–ç­›é€‰å‚æ•°
            # æ”¯æŒå¤šä¸ªnick_nameå‚æ•°ï¼ˆå¤šé€‰ï¼‰
            nick_names = request.args.getlist('nick_name')  # è·å–æ‰€æœ‰nick_nameå‚æ•°å€¼
            nick_name = request.args.get('nick_name', '').strip()  # å…¼å®¹å•ä¸ªå‚æ•°
            title = request.args.get('title', '').strip()
            create_time_start = request.args.get('create_time_start', '').strip()
            create_time_end = request.args.get('create_time_end', '').strip()
            pubtime_start = request.args.get('pubtime_start', '').strip()
            pubtime_end = request.args.get('pubtime_end', '').strip()
            
            # æ„å»ºWHEREæ¡ä»¶
            where_conditions = []
            where_params = []
            
            # å¤„ç†nick_nameç­›é€‰ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
            if nick_names and len(nick_names) > 0:
                # è¿‡æ»¤æ‰ç©ºå€¼ï¼ŒåŒæ—¶å¤„ç†URLè§£ç 
                import urllib.parse
                valid_nick_names = []
                for n in nick_names:
                    if n and n.strip():
                        # å¤„ç†URLç¼–ç çš„å‚æ•°
                        decoded = urllib.parse.unquote(n.strip())
                        valid_nick_names.append(decoded)
                if valid_nick_names:
                    # ä½¿ç”¨INæŸ¥è¯¢æ”¯æŒå¤šä¸ªå€¼
                    placeholders = ','.join(['?' for _ in valid_nick_names])
                    where_conditions.append(f'nick_name IN ({placeholders})')
                    where_params.extend(valid_nick_names)
            elif nick_name:
                # å…¼å®¹å•ä¸ªnick_nameå‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰ï¼Œå¤„ç†URLè§£ç 
                import urllib.parse
                decoded_nick_name = urllib.parse.unquote(nick_name)
                where_conditions.append('nick_name = ?')
                where_params.append(decoded_nick_name)
            
            if title:
                where_conditions.append('title LIKE ?')
                where_params.append(f'%{title}%')
            
            if create_time_start:
                where_conditions.append('created_at >= ?')
                where_params.append(create_time_start)
            
            if create_time_end:
                where_conditions.append('created_at <= ?')
                where_params.append(create_time_end)
            
            if pubtime_start:
                where_conditions.append('pubtime >= ?')
                where_params.append(pubtime_start)
            
            if pubtime_end:
                where_conditions.append('pubtime <= ?')
                where_params.append(pubtime_end)
            
            # æ„å»ºWHEREå­å¥
            where_clause = ''
            if where_conditions:
                where_clause = 'WHERE ' + ' AND '.join(where_conditions)
            
            # æŸ¥è¯¢æ€»æ•°
            count_sql = f'SELECT COUNT(*) as total FROM wechat_hotspot_articles {where_clause}'
            cursor.execute(count_sql, where_params)
            total = cursor.fetchone()['total']
            
            # æŸ¥è¯¢åˆ—è¡¨
            query_sql = f'''
                SELECT 
                    id, nick_name, biz, create_time, title, url, content, content_multi_text,
                    pubtime, read_count, zan, looking, share_num, collect_num,
                    comment_count, summary, headline, keywords, created_at, updated_at
                FROM wechat_hotspot_articles
                {where_clause}
                ORDER BY created_at DESC, id DESC
                LIMIT ? OFFSET ?
            '''
            query_params = where_params + [page_size, offset]
            cursor.execute(query_sql, query_params)
            
            rows = cursor.fetchall()
            articles = []
            for row in rows:
                # è§£ækeywords JSON
                keywords = None
                if row['keywords']:
                    try:
                        keywords = json.loads(row['keywords'])
                    except:
                        keywords = row['keywords']
                
                articles.append({
                    "id": row["id"],
                    "nick_name": row["nick_name"],
                    "biz": row["biz"],
                    "create_time": row["create_time"],
                    "title": row["title"],
                    "url": row["url"],
                    "content": row["content"],
                    "content_multi_text": row["content_multi_text"],
                    "pubtime": row["pubtime"],
                    "read": row["read_count"],
                    "zan": row["zan"],
                    "looking": row["looking"],
                    "share_num": row["share_num"],
                    "collect_num": row["collect_num"],
                    "comment_count": row["comment_count"],
                    "summary": row["summary"],
                    "headline": row["headline"],
                    "keywords": keywords,
                    "created_at": row["created_at"],
                    "updated_at": row["updated_at"]
                })
            
            return jsonify({
                "code": 200,
                "msg": "success",
                "data": {
                    "items": articles,
                    "total": total,
                    "page": page,
                    "page_size": page_size
                }
            }), 200
            
    except Exception as e:
        print(f"è·å–å…¬ä¼—å·çˆ¬å–æ–‡ç« åˆ—è¡¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"è·å–å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route('/hotspot/records', methods=['GET'])
def list_hotspot_records():
    """
    è·å–çƒ­ç‚¹ä¸­å¿ƒåˆ—è¡¨ï¼Œæ”¯æŒæŒ‰å¹³å°è¿‡æ»¤
    æ”¯æŒ article å’Œ image-text ç±»å‹ï¼Œæ‰€æœ‰è®°å½•éƒ½åŒ…å« media_ids å­—æ®µ
    """
    platform = (request.args.get('platform') or '').strip().lower()
    content_type = (request.args.get('content_type') or '').strip().lower()
    
    records = []

    try:
        import json
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            ensure_production_image_text_table(cursor)
            ensure_production_video_table(cursor)

            # è·å–æ–‡ç« è®°å½•
            if not content_type or content_type in ('all', 'article'):
                cursor.execute('''
                    SELECT id,
                           article_title,
                           article_content,
                           article_desc,
                           article_media_id,
                           article_media_url,
                           COALESCE(publish_status, 'pending') as publish_status,
                           created_at
                    FROM production_articles
                    ORDER BY created_at DESC, id DESC
                ''')
                article_rows = cursor.fetchall()

                for row in article_rows:
                    # å°† media_id è½¬æ¢ä¸º media_ids æ•°ç»„æ ¼å¼
                    media_id = row["article_media_id"] or ""
                    media_ids = [media_id] if media_id else []
                    
                    records.append({
                        "id": row["id"],
                        "content_type": "article",
                        "title": row["article_title"],
                        "summary": row["article_desc"] or "",
                        "content": row["article_content"],
                        "media_id": row["article_media_id"],
                        "media_url": row["article_media_url"],
                        "media_ids": media_ids,  # åŒ…å« media_ids å­—æ®µ
                        "publish_status": row["publish_status"] or "pending",  # å‘å¸ƒçŠ¶æ€
                        "created_at": row["created_at"]
                    })

            # è·å–å›¾æ–‡è®°å½•
            if not content_type or content_type in ('all', 'image-text'):
                cursor.execute('''
                    SELECT id,
                           title,
                           content,
                           media_ids,
                           height,
                           width,
                           url,
                           COALESCE(publish_status, 'pending') as publish_status,
                           created_at
                    FROM production_image_text
                    ORDER BY created_at DESC, id DESC
                ''')
                image_text_rows = cursor.fetchall()

                for row in image_text_rows:
                    # è§£æ media_ids JSON å­—ç¬¦ä¸²ä¸ºæ•°ç»„
                    try:
                        media_ids = json.loads(row["media_ids"]) if row["media_ids"] else []
                    except:
                        media_ids = []
                    
                    records.append({
                        "id": row["id"],
                        "content_type": "image-text",
                        "title": row["title"],
                        "summary": "",  # å›¾æ–‡ç±»å‹æ²¡æœ‰æ‘˜è¦å­—æ®µ
                        "content": row["content"],
                        "media_ids": media_ids,  # åŒ…å« media_ids å­—æ®µ
                        "height": row["height"],
                        "width": row["width"],
                        "url": row["url"],  # æ·»åŠ  url å­—æ®µ
                        "publish_status": row["publish_status"] or "pending",  # å‘å¸ƒçŠ¶æ€
                        "created_at": row["created_at"]
                    })

    except Exception as e:
        print(f"è·å–çƒ­ç‚¹è®°å½•å¤±è´¥: {e}")
        return jsonify({
            "code": 500,
            "msg": f"è·å–çƒ­ç‚¹è®°å½•å¤±è´¥: {str(e)}",
            "data": None
        }), 500

    # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    records.sort(key=lambda x: (x.get('created_at') or '', x.get('id', 0)), reverse=True)
    
    # å¯æŒ‰ content_type è¿‡æ»¤
    if content_type and content_type not in ('all', ''):
        filtered = [record for record in records if record["content_type"] == content_type]
    else:
        filtered = records

    return jsonify({
        "code": 200,
        "msg": "success",
        "data": {
            "items": filtered,
            "total": len(filtered)
        }
    }), 200


@app.route('/production/records/<int:record_id>', methods=['DELETE'])
def delete_production_record(record_id):
    """
    åˆ é™¤æŒ‡å®šçš„åˆ¶ä½œè®°å½•ï¼ˆæ”¯æŒæ–‡ç« ã€å›¾æ–‡å’Œè§†é¢‘è®°å½•ï¼‰
    æŸ¥è¯¢å‚æ•°: content_type (å¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ç›´æ¥æ“ä½œå¯¹åº”è¡¨ï¼Œå¦åˆ™å°è¯•ä¸‰å¼ è¡¨)
    æ”¯æŒ: article, image-text, video
    """
    try:
        content_type = (request.args.get('content_type') or '').strip().lower()
        
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            ensure_production_image_text_table(cursor)
            ensure_production_video_table(cursor)

            # å¦‚æœæä¾›äº† content_typeï¼Œç›´æ¥æ“ä½œå¯¹åº”çš„è¡¨ï¼ˆæ›´é«˜æ•ˆï¼‰
            if content_type == 'article':
                cursor.execute('SELECT id FROM production_articles WHERE id = ?', (record_id,))
                if cursor.fetchone():
                    cursor.execute('DELETE FROM production_articles WHERE id = ?', (record_id,))
                    conn.commit()
                    return jsonify({
                        "code": 200,
                        "msg": "æ–‡ç« è®°å½•å·²åˆ é™¤",
                        "data": {"id": record_id, "content_type": "article"}
                    }), 200
                return jsonify({
                    "code": 404,
                    "msg": "æ–‡ç« è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
            elif content_type == 'image-text':
                cursor.execute('SELECT id FROM production_image_text WHERE id = ?', (record_id,))
                if cursor.fetchone():
                    cursor.execute('DELETE FROM production_image_text WHERE id = ?', (record_id,))
                    conn.commit()
                    return jsonify({
                        "code": 200,
                        "msg": "å›¾æ–‡è®°å½•å·²åˆ é™¤",
                        "data": {"id": record_id, "content_type": "image-text"}
                    }), 200
                return jsonify({
                    "code": 404,
                    "msg": "å›¾æ–‡è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
            elif content_type == 'video':
                cursor.execute('SELECT id FROM production_video WHERE id = ?', (record_id,))
                if cursor.fetchone():
                    cursor.execute('DELETE FROM production_video WHERE id = ?', (record_id,))
                    conn.commit()
                    return jsonify({
                        "code": 200,
                        "msg": "è§†é¢‘è®°å½•å·²åˆ é™¤",
                        "data": {"id": record_id, "content_type": "video"}
                    }), 200
                return jsonify({
                    "code": 404,
                    "msg": "è§†é¢‘è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
            # å¦‚æœæ²¡æœ‰æä¾› content_typeï¼Œå°è¯•ä¸‰å¼ è¡¨ï¼ˆå‘åå…¼å®¹ï¼‰
            # å…ˆå°è¯•ä»æ–‡ç« è¡¨åˆ é™¤
            cursor.execute('SELECT id FROM production_articles WHERE id = ?', (record_id,))
            if cursor.fetchone():
                cursor.execute('DELETE FROM production_articles WHERE id = ?', (record_id,))
                conn.commit()
                return jsonify({
                    "code": 200,
                    "msg": "åˆ¶ä½œè®°å½•å·²åˆ é™¤",
                    "data": {"id": record_id, "content_type": "article"}
                }), 200
            
            # å†å°è¯•ä»å›¾æ–‡è¡¨åˆ é™¤
            cursor.execute('SELECT id FROM production_image_text WHERE id = ?', (record_id,))
            if cursor.fetchone():
                cursor.execute('DELETE FROM production_image_text WHERE id = ?', (record_id,))
                conn.commit()
                return jsonify({
                    "code": 200,
                    "msg": "åˆ¶ä½œè®°å½•å·²åˆ é™¤",
                    "data": {"id": record_id, "content_type": "image-text"}
                }), 200
            
            # å†å°è¯•ä»è§†é¢‘è¡¨åˆ é™¤
            cursor.execute('SELECT id FROM production_video WHERE id = ?', (record_id,))
            if cursor.fetchone():
                cursor.execute('DELETE FROM production_video WHERE id = ?', (record_id,))
                conn.commit()
                return jsonify({
                    "code": 200,
                    "msg": "åˆ¶ä½œè®°å½•å·²åˆ é™¤",
                    "data": {"id": record_id, "content_type": "video"}
                }), 200
            
            # éƒ½ä¸å­˜åœ¨
            return jsonify({
                "code": 404,
                "msg": "åˆ¶ä½œè®°å½•ä¸å­˜åœ¨",
                "data": None
            }), 404

    except Exception as e:
        print(f"åˆ é™¤åˆ¶ä½œè®°å½•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"åˆ é™¤å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route('/production/records', methods=['DELETE'])
def batch_delete_production_records():
    """
    æ‰¹é‡åˆ é™¤åˆ¶ä½œè®°å½•ï¼ˆæ”¯æŒæ–‡ç« ã€å›¾æ–‡å’Œè§†é¢‘è®°å½•ï¼‰
    è¯·æ±‚ä½“æ ¼å¼1ï¼ˆæ¨èï¼Œæ›´é«˜æ•ˆï¼‰: { "content_type": "article", "ids": [1, 2, 3] }
    è¯·æ±‚ä½“æ ¼å¼2ï¼ˆå…¼å®¹ï¼‰: { "ids": [1, 2, 3] } - ä¼šè‡ªåŠ¨ä»ä¸‰å¼ è¡¨ä¸­æŸ¥æ‰¾
    """
    try:
        data = request.get_json()
        if not data or 'ids' not in data:
            return jsonify({
                "code": 400,
                "msg": "è¯·æ±‚å‚æ•°é”™è¯¯ï¼Œéœ€è¦æä¾› ids æ•°ç»„",
                "data": None
            }), 400
        
        ids = data.get('ids', [])
        if not isinstance(ids, list) or len(ids) == 0:
            return jsonify({
                "code": 400,
                "msg": "ids å¿…é¡»æ˜¯éç©ºæ•°ç»„",
                "data": None
            }), 400
        
        content_type = (data.get('content_type') or '').strip().lower()
        
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            ensure_production_image_text_table(cursor)
            ensure_production_video_table(cursor)
            
            # å¦‚æœæä¾›äº† content_typeï¼Œç›´æ¥æ“ä½œå¯¹åº”çš„è¡¨ï¼ˆæ›´é«˜æ•ˆï¼‰
            if content_type == 'article':
                placeholders = ','.join(['?'] * len(ids))
                cursor.execute(f'SELECT id FROM production_articles WHERE id IN ({placeholders})', ids)
                existing_ids = [row[0] for row in cursor.fetchall()]
                
                if len(existing_ids) != len(ids):
                    missing_ids = set(ids) - set(existing_ids)
                    return jsonify({
                        "code": 404,
                        "msg": f"éƒ¨åˆ†æ–‡ç« è®°å½•ä¸å­˜åœ¨: {list(missing_ids)}",
                        "data": None
                    }), 404
                
                cursor.execute(f'DELETE FROM production_articles WHERE id IN ({placeholders})', ids)
                deleted_count = cursor.rowcount
                conn.commit()
                
                return jsonify({
                    "code": 200,
                    "msg": f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡æ–‡ç« è®°å½•",
                    "data": {
                        "deleted_count": deleted_count,
                        "deleted_ids": ids,
                        "content_type": "article"
                    }
                }), 200
            
            elif content_type == 'image-text':
                placeholders = ','.join(['?'] * len(ids))
                cursor.execute(f'SELECT id FROM production_image_text WHERE id IN ({placeholders})', ids)
                existing_ids = [row[0] for row in cursor.fetchall()]
                
                if len(existing_ids) != len(ids):
                    missing_ids = set(ids) - set(existing_ids)
                    return jsonify({
                        "code": 404,
                        "msg": f"éƒ¨åˆ†å›¾æ–‡è®°å½•ä¸å­˜åœ¨: {list(missing_ids)}",
                        "data": None
                    }), 404
                
                cursor.execute(f'DELETE FROM production_image_text WHERE id IN ({placeholders})', ids)
                deleted_count = cursor.rowcount
                conn.commit()
                
                return jsonify({
                    "code": 200,
                    "msg": f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡å›¾æ–‡è®°å½•",
                    "data": {
                        "deleted_count": deleted_count,
                        "deleted_ids": ids,
                        "content_type": "image-text"
                    }
                }), 200
            
            elif content_type == 'video':
                placeholders = ','.join(['?'] * len(ids))
                cursor.execute(f'SELECT id FROM production_video WHERE id IN ({placeholders})', ids)
                existing_ids = [row[0] for row in cursor.fetchall()]
                
                if len(existing_ids) != len(ids):
                    missing_ids = set(ids) - set(existing_ids)
                    return jsonify({
                        "code": 404,
                        "msg": f"éƒ¨åˆ†è§†é¢‘è®°å½•ä¸å­˜åœ¨: {list(missing_ids)}",
                        "data": None
                    }), 404
                
                cursor.execute(f'DELETE FROM production_video WHERE id IN ({placeholders})', ids)
                deleted_count = cursor.rowcount
                conn.commit()
                
                return jsonify({
                    "code": 200,
                    "msg": f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡è§†é¢‘è®°å½•",
                    "data": {
                        "deleted_count": deleted_count,
                        "deleted_ids": ids,
                        "content_type": "video"
                    }
                }), 200
            
            # å¦‚æœæ²¡æœ‰æä¾› content_typeï¼Œä»ä¸‰å¼ è¡¨ä¸­æŸ¥æ‰¾ï¼ˆå‘åå…¼å®¹ï¼‰
            placeholders = ','.join(['?'] * len(ids))
            
            # ä»æ–‡ç« è¡¨æŸ¥æ‰¾
            cursor.execute(f'SELECT id FROM production_articles WHERE id IN ({placeholders})', ids)
            article_ids = [row[0] for row in cursor.fetchall()]
            
            # ä»å›¾æ–‡è¡¨æŸ¥æ‰¾
            cursor.execute(f'SELECT id FROM production_image_text WHERE id IN ({placeholders})', ids)
            image_text_ids = [row[0] for row in cursor.fetchall()]
            
            # ä»è§†é¢‘è¡¨æŸ¥æ‰¾
            cursor.execute(f'SELECT id FROM production_video WHERE id IN ({placeholders})', ids)
            video_ids = [row[0] for row in cursor.fetchall()]
            
            existing_ids = set(article_ids + image_text_ids + video_ids)
            
            if len(existing_ids) != len(ids):
                missing_ids = set(ids) - existing_ids
                return jsonify({
                    "code": 404,
                    "msg": f"éƒ¨åˆ†è®°å½•ä¸å­˜åœ¨: {list(missing_ids)}",
                    "data": None
                }), 404
            
            # æ‰¹é‡åˆ é™¤æ–‡ç« è®°å½•
            deleted_article_count = 0
            if article_ids:
                article_placeholders = ','.join(['?'] * len(article_ids))
                cursor.execute(f'DELETE FROM production_articles WHERE id IN ({article_placeholders})', article_ids)
                deleted_article_count = cursor.rowcount
            
            # æ‰¹é‡åˆ é™¤å›¾æ–‡è®°å½•
            deleted_image_text_count = 0
            if image_text_ids:
                image_text_placeholders = ','.join(['?'] * len(image_text_ids))
                cursor.execute(f'DELETE FROM production_image_text WHERE id IN ({image_text_placeholders})', image_text_ids)
                deleted_image_text_count = cursor.rowcount
            
            # æ‰¹é‡åˆ é™¤è§†é¢‘è®°å½•
            deleted_video_count = 0
            if video_ids:
                video_placeholders = ','.join(['?'] * len(video_ids))
                cursor.execute(f'DELETE FROM production_video WHERE id IN ({video_placeholders})', video_ids)
                deleted_video_count = cursor.rowcount
            
            conn.commit()
            total_deleted = deleted_article_count + deleted_image_text_count + deleted_video_count
        
        return jsonify({
            "code": 200,
            "msg": f"æˆåŠŸåˆ é™¤ {total_deleted} æ¡è®°å½•ï¼ˆæ–‡ç« : {deleted_article_count}, å›¾æ–‡: {deleted_image_text_count}, è§†é¢‘: {deleted_video_count}ï¼‰",
            "data": {
                "deleted_count": total_deleted,
                "deleted_ids": ids,
                "details": {
                    "article": deleted_article_count,
                    "image_text": deleted_image_text_count,
                    "video": deleted_video_count
                }
            }
        }), 200
    
    except Exception as e:
        print(f"æ‰¹é‡åˆ é™¤åˆ¶ä½œè®°å½•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"æ‰¹é‡åˆ é™¤å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/production/records/<int:record_id>/status', methods=['PUT'])
def update_production_record_status(record_id):
    """
    æ›´æ–°åˆ¶ä½œä¸­å¿ƒè®°å½•çš„å‘å¸ƒçŠ¶æ€
    è¯·æ±‚ä½“: { "status": "pending" | "processing" | "creating" | "success" | "failed", "content_type": "article" | "image-text" | "video" (å¯é€‰) }
    å¦‚æœæä¾›äº† content_typeï¼Œç›´æ¥æ“ä½œå¯¹åº”çš„è¡¨ï¼ˆæ›´é«˜æ•ˆï¼‰
    """
    try:
        data = request.get_json(silent=True) or {}
        status = data.get('status', '').strip().lower()
        content_type = (data.get('content_type') or '').strip().lower()
        
        # éªŒè¯çŠ¶æ€å€¼
        valid_statuses = ['pending', 'processing', 'creating', 'success', 'failed']
        if status not in valid_statuses:
            return jsonify({
                "code": 400,
                "msg": f"æ— æ•ˆçš„çŠ¶æ€å€¼ï¼Œå¿…é¡»æ˜¯: {', '.join(valid_statuses)}",
                "data": None
            }), 400
        
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            ensure_production_image_text_table(cursor)
            ensure_production_video_table(cursor)
            
            # å¦‚æœæä¾›äº† content_typeï¼Œç›´æ¥æ“ä½œå¯¹åº”çš„è¡¨ï¼ˆæ›´é«˜æ•ˆï¼‰
            if content_type == 'article':
                cursor.execute('SELECT id FROM production_articles WHERE id = ?', (record_id,))
                if cursor.fetchone():
                    cursor.execute('''
                        UPDATE production_articles 
                        SET publish_status = ? 
                        WHERE id = ?
                    ''', (status, record_id))
                    conn.commit()
                    return jsonify({
                        "code": 200,
                        "msg": "æ–‡ç« è®°å½•çŠ¶æ€å·²æ›´æ–°",
                        "data": {
                            "id": record_id,
                            "status": status,
                            "content_type": "article"
                        }
                    }), 200
                return jsonify({
                    "code": 404,
                    "msg": "æ–‡ç« è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
            elif content_type == 'image-text':
                cursor.execute('SELECT id FROM production_image_text WHERE id = ?', (record_id,))
                if cursor.fetchone():
                    cursor.execute('''
                        UPDATE production_image_text 
                        SET publish_status = ? 
                        WHERE id = ?
                    ''', (status, record_id))
                    conn.commit()
                    return jsonify({
                        "code": 200,
                        "msg": "å›¾æ–‡è®°å½•çŠ¶æ€å·²æ›´æ–°",
                        "data": {
                            "id": record_id,
                            "status": status,
                            "content_type": "image-text"
                        }
                    }), 200
                return jsonify({
                    "code": 404,
                    "msg": "å›¾æ–‡è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
            elif content_type == 'video':
                cursor.execute('SELECT id FROM production_video WHERE id = ?', (record_id,))
                if cursor.fetchone():
                    cursor.execute('''
                        UPDATE production_video 
                        SET publish_status = ? 
                        WHERE id = ?
                    ''', (status, record_id))
                    conn.commit()
                    return jsonify({
                        "code": 200,
                        "msg": "è§†é¢‘è®°å½•çŠ¶æ€å·²æ›´æ–°",
                        "data": {
                            "id": record_id,
                            "status": status,
                            "content_type": "video"
                        }
                    }), 200
                return jsonify({
                    "code": 404,
                    "msg": "è§†é¢‘è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
            # å¦‚æœæ²¡æœ‰æä¾› content_typeï¼Œå°è¯•ä¸‰å¼ è¡¨ï¼ˆå‘åå…¼å®¹ï¼‰
            # å…ˆå°è¯•æ›´æ–°æ–‡ç« è¡¨
            cursor.execute('SELECT id FROM production_articles WHERE id = ?', (record_id,))
            if cursor.fetchone():
                cursor.execute('''
                    UPDATE production_articles 
                    SET publish_status = ? 
                    WHERE id = ?
                ''', (status, record_id))
                conn.commit()
                return jsonify({
                    "code": 200,
                    "msg": "åˆ¶ä½œä¸­å¿ƒè®°å½•çŠ¶æ€å·²æ›´æ–°",
                    "data": {
                        "id": record_id,
                        "status": status,
                        "content_type": "article"
                    }
                }), 200
            
            # å†å°è¯•æ›´æ–°å›¾æ–‡è¡¨
            cursor.execute('SELECT id FROM production_image_text WHERE id = ?', (record_id,))
            if cursor.fetchone():
                cursor.execute('''
                    UPDATE production_image_text 
                    SET publish_status = ? 
                    WHERE id = ?
                ''', (status, record_id))
                conn.commit()
                return jsonify({
                    "code": 200,
                    "msg": "åˆ¶ä½œä¸­å¿ƒè®°å½•çŠ¶æ€å·²æ›´æ–°",
                    "data": {
                        "id": record_id,
                        "status": status,
                        "content_type": "image-text"
                    }
                }), 200
            
            # å†å°è¯•æ›´æ–°è§†é¢‘è¡¨
            cursor.execute('SELECT id FROM production_video WHERE id = ?', (record_id,))
            if cursor.fetchone():
                cursor.execute('''
                    UPDATE production_video 
                    SET publish_status = ? 
                    WHERE id = ?
                ''', (status, record_id))
                conn.commit()
                return jsonify({
                    "code": 200,
                    "msg": "åˆ¶ä½œä¸­å¿ƒè®°å½•çŠ¶æ€å·²æ›´æ–°",
                    "data": {
                        "id": record_id,
                        "status": status,
                        "content_type": "video"
                    }
                }), 200
            
            # è®°å½•ä¸å­˜åœ¨
            return jsonify({
                "code": 404,
                "msg": "è®°å½•ä¸å­˜åœ¨",
                "data": None
            }), 404
    
    except Exception as e:
        print(f"æ›´æ–°åˆ¶ä½œä¸­å¿ƒè®°å½•çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({
            "code": 500,
            "msg": f"æ›´æ–°çŠ¶æ€å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/production/image-text/<int:record_id>', methods=['PUT'])
def update_production_image_text(record_id):
    """
    æ›´æ–°å›¾æ–‡è®°å½•å†…å®¹
    å‚æ•°: title, content, media_ids (æ•°ç»„), height, width, url (å¯é€‰)
    """
    data = request.get_json(silent=True) or {}
    
    try:
        import json
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_image_text_table(cursor)
            
            # æ£€æŸ¥è®°å½•æ˜¯å¦å­˜åœ¨
            cursor.execute('SELECT id FROM production_image_text WHERE id = ?', (record_id,))
            if not cursor.fetchone():
                return jsonify({
                    "code": 404,
                    "msg": "è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
            # å°† media_ids æ•°ç»„è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²å­˜å‚¨
            media_ids = data.get('media_ids', [])
            if not isinstance(media_ids, list):
                return jsonify({
                    "code": 400,
                    "msg": "media_ids å¿…é¡»æ˜¯æ•°ç»„",
                    "data": None
                }), 400
            
            media_ids_json = json.dumps(media_ids, ensure_ascii=False)
            
            # è·å– url å‚æ•°ï¼ˆå¯é€‰ï¼‰
            url = data.get('url', '').strip() if data.get('url') else None
            
            # æ›´æ–°è®°å½•
            cursor.execute('''
                UPDATE production_image_text
                SET title = ?,
                    content = ?,
                    media_ids = ?,
                    height = ?,
                    width = ?,
                    url = ?
                WHERE id = ?
            ''', (
                data.get('title', '').strip(),
                data.get('content', '').strip(),
                media_ids_json,
                data.get('height'),
                data.get('width'),
                url,
                record_id
            ))
            conn.commit()
        
        return jsonify({
            "code": 200,
            "msg": "å›¾æ–‡ä¿¡æ¯å·²æ›´æ–°",
            "data": {
                "id": record_id
            }
        }), 200
    
    except Exception as e:
        print(f"æ›´æ–°å›¾æ–‡ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({
            "code": 500,
            "msg": f"æ›´æ–°å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/production/articles/<int:record_id>', methods=['PUT'])
def update_production_article(record_id):
    """
    æ›´æ–°æ–‡ç« è®°å½•å†…å®¹
    å‚æ•°: title, content, desc, url, html
    """
    data = request.get_json(silent=True) or {}
    
    try:
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            
            # æ£€æŸ¥è®°å½•æ˜¯å¦å­˜åœ¨
            cursor.execute('SELECT id FROM production_articles WHERE id = ?', (record_id,))
            if not cursor.fetchone():
                return jsonify({
                    "code": 404,
                    "msg": "è®°å½•ä¸å­˜åœ¨",
                    "data": None
                }), 404
            
            # æ£€æŸ¥è¡¨ç»“æ„
            cursor.execute("PRAGMA table_info(production_articles)")
            columns = [row[1] for row in cursor.fetchall()]
            has_new_fields = 'title' in columns and 'content' in columns
            has_old_fields = 'article_title' in columns and 'article_content' in columns
            
            title = data.get('title', '').strip()
            content = data.get('content', '').strip()
            desc = data.get('desc', '').strip()
            url = data.get('url', '').strip()
            html = data.get('html', '').strip()
            
            if has_new_fields and has_old_fields:
                # åŒæ—¶æ›´æ–°æ–°æ—§å­—æ®µï¼ˆå…¼å®¹ï¼‰
                cursor.execute('''
                    UPDATE production_articles
                    SET title = ?,
                        content = ?,
                        desc = ?,
                        url = ?,
                        html = ?,
                        article_title = ?,
                        article_content = ?,
                        article_desc = ?,
                        article_media_url = ?
                    WHERE id = ?
                ''', (
                    title, content, desc, url, html,
                    title, content, desc, url,  # æ—§å­—æ®µä¹Ÿæ›´æ–°
                    record_id
                ))
            elif has_new_fields:
                # åªæ›´æ–°æ–°å­—æ®µ
                cursor.execute('''
                    UPDATE production_articles
                    SET title = ?,
                        content = ?,
                        desc = ?,
                        url = ?,
                        html = ?
                    WHERE id = ?
                ''', (title, content, desc, url, html, record_id))
            else:
                # åªæ›´æ–°æ—§å­—æ®µï¼ˆå…¼å®¹ï¼‰
                cursor.execute('''
                    UPDATE production_articles
                    SET article_title = ?,
                        article_content = ?,
                        article_desc = ?,
                        article_media_url = ?
                    WHERE id = ?
                ''', (title, content, desc, url, record_id))
            
            conn.commit()
        
        return jsonify({
            "code": 200,
            "msg": "æ–‡ç« ä¿¡æ¯å·²æ›´æ–°",
            "data": {
                "id": record_id
            }
        }), 200
    
    except Exception as e:
        print(f"æ›´æ–°æ–‡ç« ä¿¡æ¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"æ›´æ–°å¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/publish/records', methods=['GET'])
def list_publish_records():
    """
    è·å–å‘å¸ƒä¸­å¿ƒè®°å½•åˆ—è¡¨ï¼Œå¯æŒ‰ content_type è¿‡æ»¤
    è¿”å›æ‰€æœ‰å‘å¸ƒçŠ¶æ€ä¸º success çš„è®°å½•
    """
    content_type = (request.args.get('content_type') or '').strip().lower()
    supported_types = {'', 'all', 'article', 'image-text', 'video'}
    
    if content_type and content_type not in supported_types:
        return jsonify({
            "code": 200,
            "msg": "success",
            "data": []
        }), 200
    
    records = []
    
    try:
        import json
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            ensure_production_image_text_table(cursor)
            ensure_production_video_table(cursor)
            
            # è·å–æ–‡ç« è®°å½•ï¼ˆåªè¿”å›å‘å¸ƒæˆåŠŸçš„ï¼‰
            if not content_type or content_type in ('all', 'article'):
                # æ£€æŸ¥è¡¨ç»“æ„ï¼Œä¼˜å…ˆä½¿ç”¨æ–°å­—æ®µ
                cursor.execute("PRAGMA table_info(production_articles)")
                columns = [row[1] for row in cursor.fetchall()]
                has_new_fields = 'title' in columns and 'content' in columns
                has_old_fields = 'article_title' in columns
                
                if has_new_fields:
                    # ä½¿ç”¨æ–°å­—æ®µï¼ˆä¼˜å…ˆï¼‰ï¼Œåªåœ¨æ—§å­—æ®µå­˜åœ¨æ—¶æ‰å°è¯•å…¼å®¹
                    if has_old_fields:
                        cursor.execute('''
                            SELECT id,
                                   COALESCE(NULLIF(title, ''), article_title, '') as title,
                                   COALESCE(NULLIF(content, ''), article_content, '') as content,
                                   COALESCE(NULLIF(desc, ''), article_desc, '') as desc,
                                   COALESCE(NULLIF(url, ''), article_media_url, '') as url,
                                   COALESCE(html, '') as html,
                                   COALESCE(publish_status, 'pending') as publish_status,
                                   created_at
                            FROM production_articles
                            WHERE publish_status = 'success'
                            ORDER BY created_at DESC, id DESC
                        ''')
                    else:
                        # åªæœ‰æ–°å­—æ®µï¼Œç›´æ¥ä½¿ç”¨
                        cursor.execute('''
                            SELECT id,
                                   COALESCE(title, '') as title,
                                   COALESCE(content, '') as content,
                                   COALESCE(desc, '') as desc,
                                   COALESCE(url, '') as url,
                                   COALESCE(html, '') as html,
                                   COALESCE(publish_status, 'pending') as publish_status,
                                   created_at
                            FROM production_articles
                            WHERE publish_status = 'success'
                            ORDER BY created_at DESC, id DESC
                        ''')
                    article_rows = cursor.fetchall()
                else:
                    # å…¼å®¹æ—§å­—æ®µ
                    if has_old_fields:
                        cursor.execute('''
                            SELECT id,
                                   article_title as title,
                                   article_content as content,
                                   article_desc as desc,
                                   article_media_url as url,
                                   '' as html,
                                   COALESCE(publish_status, 'pending') as publish_status,
                                   created_at
                            FROM production_articles
                            WHERE publish_status = 'success'
                            ORDER BY created_at DESC, id DESC
                        ''')
                        article_rows = cursor.fetchall()
                    else:
                        # æ—¢æ²¡æœ‰æ–°å­—æ®µä¹Ÿæ²¡æœ‰æ—§å­—æ®µï¼Œè·³è¿‡æŸ¥è¯¢
                        article_rows = []
                
                # å¤„ç†æŸ¥è¯¢ç»“æœ
                for row in article_rows:
                    records.append({
                        "id": row["id"],
                        "content_type": "article",
                        "title": row["title"] or "",
                        "content": row["content"] or "",
                        "desc": row["desc"] or "",
                        "url": row["url"] or "",
                        "html": row["html"] or "",
                        "summary": row["desc"] or "",  # å…¼å®¹å­—æ®µ
                        "publish_status": row["publish_status"] or "pending",
                        "created_at": row["created_at"] or ""
                    })
            
            # è·å–å›¾æ–‡è®°å½•ï¼ˆåªè¿”å›å‘å¸ƒæˆåŠŸçš„ï¼‰
            if not content_type or content_type in ('all', 'image-text'):
                try:
                    cursor.execute('''
                        SELECT id,
                               title,
                               content,
                               media_ids,
                               height,
                               width,
                               url,
                               COALESCE(publish_status, 'pending') as publish_status,
                               created_at
                        FROM production_image_text
                        WHERE publish_status = 'success'
                        ORDER BY created_at DESC, id DESC
                    ''')
                except sqlite3.OperationalError:
                    # å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨ç®€åŒ–æŸ¥è¯¢
                    cursor.execute('''
                        SELECT id,
                               title,
                               content,
                               media_ids,
                               url,
                               COALESCE(publish_status, 'pending') as publish_status,
                               created_at
                        FROM production_image_text
                        WHERE publish_status = 'success'
                        ORDER BY created_at DESC, id DESC
                    ''')
                
                image_text_rows = cursor.fetchall()
                
                for row in image_text_rows:
                    try:
                        media_ids = json.loads(row["media_ids"]) if row["media_ids"] else []
                    except:
                        media_ids = []
                    
                    # å®‰å…¨è·å–å¯é€‰å­—æ®µ
                    height = row["height"] if "height" in row.keys() else None
                    width = row["width"] if "width" in row.keys() else None
                    
                    records.append({
                        "id": row["id"],
                        "content_type": "image-text",
                        "title": row["title"] or "",
                        "summary": "",
                        "content": row["content"] or "",
                        "media_ids": media_ids,
                        "height": height,
                        "width": width,
                        "url": row["url"] or "",
                        "publish_status": row["publish_status"] or "pending",
                        "created_at": row["created_at"] or ""
                    })
            
            # è·å–è§†é¢‘è®°å½•ï¼ˆåªè¿”å›å‘å¸ƒæˆåŠŸçš„ï¼‰
            if not content_type or content_type in ('all', 'video'):
                try:
                    cursor.execute('''
                        SELECT id,
                               title,
                               content,
                               "desc",
                               keywords,
                               video,
                               material_url,
                               COALESCE(publish_status, 'pending') as publish_status,
                               created_at
                        FROM production_video
                        WHERE publish_status = 'success'
                        ORDER BY created_at DESC, id DESC
                    ''')
                except sqlite3.OperationalError:
                    # å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨ç®€åŒ–æŸ¥è¯¢
                    try:
                        cursor.execute('''
                            SELECT id,
                                   title,
                                   content,
                                   keywords,
                                   video,
                                   material_url,
                                   COALESCE(publish_status, 'pending') as publish_status,
                                   created_at
                            FROM production_video
                            WHERE publish_status = 'success'
                            ORDER BY created_at DESC, id DESC
                        ''')
                    except sqlite3.OperationalError:
                        # å¦‚æœmaterial_urlä¹Ÿä¸å­˜åœ¨ï¼Œä½¿ç”¨æœ€ç®€æŸ¥è¯¢
                        cursor.execute('''
                            SELECT id,
                                   title,
                                   content,
                                   keywords,
                                   video,
                                   COALESCE(publish_status, 'pending') as publish_status,
                                   created_at
                            FROM production_video
                            WHERE publish_status = 'success'
                            ORDER BY created_at DESC, id DESC
                        ''')
                
                video_rows = cursor.fetchall()
                
                for row in video_rows:
                    keywords = row["keywords"] or ""
                    try:
                        keywords_list = json.loads(keywords) if keywords else []
                    except:
                        keywords_list = [k.strip() for k in keywords.split(',')] if keywords else []
                    
                    # å®‰å…¨è·å–descå­—æ®µ
                    desc_value = ""
                    row_keys = [k.lower() for k in row.keys()]
                    if 'desc' in row_keys:
                        for key in row.keys():
                            if key.lower() == 'desc':
                                desc_value = row[key] or ""
                                break
                    
                    # å®‰å…¨è·å–material_urlå­—æ®µ
                    material_url = row["material_url"] if "material_url" in row.keys() else ""
                    
                    records.append({
                        "id": row["id"],
                        "content_type": "video",
                        "title": row["title"] or "",
                        "summary": desc_value,
                        "content": row["content"] or "",
                        "keywords": keywords_list,
                        "video": row["video"] or "",
                        "material_url": material_url,
                        "publish_status": row["publish_status"] or "pending",
                        "created_at": row["created_at"] or ""
                    })
    
    except Exception as e:
        print(f"è·å–å‘å¸ƒè®°å½•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"è·å–å‘å¸ƒè®°å½•å¤±è´¥: {str(e)}",
            "data": None
        }), 500
    
    # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åº
    records.sort(key=lambda x: (x.get('created_at') or '', x.get('id', 0)), reverse=True)
    
    # å¯æŒ‰ content_type è¿‡æ»¤
    if content_type and content_type not in ('all', ''):
        filtered = [record for record in records if record["content_type"] == content_type]
    else:
        filtered = records
    
    return jsonify({
        "code": 200,
        "msg": "success",
        "data": filtered
    }), 200


@app.route('/publish/records/<int:record_id>/status', methods=['PUT'])
def update_publish_record_status(record_id):
    """
    æ›´æ–°å‘å¸ƒä¸­å¿ƒè®°å½•çš„å‘å¸ƒçŠ¶æ€
    è¯·æ±‚ä½“: { "status": "pending" | "processing" | "success" | "failed" }
    """
    try:
        data = request.get_json(silent=True) or {}
        status = data.get('status', '').strip().lower()
        
        # éªŒè¯çŠ¶æ€å€¼
        valid_statuses = ['pending', 'processing', 'success', 'failed']
        if status not in valid_statuses:
            return jsonify({
                "code": 400,
                "msg": f"æ— æ•ˆçš„çŠ¶æ€å€¼ï¼Œå¿…é¡»æ˜¯: {', '.join(valid_statuses)}",
                "data": None
            }), 400
        
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            ensure_production_article_table(cursor)
            ensure_production_image_text_table(cursor)
            
            # å…ˆå°è¯•æ›´æ–°æ–‡ç« è¡¨
            cursor.execute('SELECT id FROM production_articles WHERE id = ?', (record_id,))
            if cursor.fetchone():
                cursor.execute('''
                    UPDATE production_articles 
                    SET publish_status = ? 
                    WHERE id = ?
                ''', (status, record_id))
                conn.commit()
                return jsonify({
                    "code": 200,
                    "msg": "å‘å¸ƒä¸­å¿ƒè®°å½•çŠ¶æ€å·²æ›´æ–°",
                    "data": {
                        "id": record_id,
                        "status": status
                    }
                }), 200
            
            # å†å°è¯•æ›´æ–°å›¾æ–‡è¡¨
            cursor.execute('SELECT id FROM production_image_text WHERE id = ?', (record_id,))
            if cursor.fetchone():
                cursor.execute('''
                    UPDATE production_image_text 
                    SET publish_status = ? 
                    WHERE id = ?
                ''', (status, record_id))
                conn.commit()
                return jsonify({
                    "code": 200,
                    "msg": "å‘å¸ƒä¸­å¿ƒè®°å½•çŠ¶æ€å·²æ›´æ–°",
                    "data": {
                        "id": record_id,
                        "status": status
                    }
                }), 200
            
            # è®°å½•ä¸å­˜åœ¨
            return jsonify({
                "code": 404,
                "msg": "è®°å½•ä¸å­˜åœ¨",
                "data": None
            }), 404
    
    except Exception as e:
        print(f"æ›´æ–°å‘å¸ƒä¸­å¿ƒè®°å½•çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({
            "code": 500,
            "msg": f"æ›´æ–°çŠ¶æ€å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route('/deleteFile', methods=['GET'])
def delete_file():
    file_id = request.args.get('id')

    if not file_id or not file_id.isdigit():
        return jsonify({
            "code": 400,
            "msg": "Invalid or missing file ID",
            "data": None
        }), 400

    try:
        # è·å–æ•°æ®åº“è¿æ¥
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # æŸ¥è¯¢è¦åˆ é™¤çš„è®°å½•
            cursor.execute("SELECT * FROM file_records WHERE id = ?", (file_id,))
            record = cursor.fetchone()

            if not record:
                return jsonify({
                    "code": 404,
                    "msg": "File not found",
                    "data": None
                }), 404

            record = dict(record)

            # è·å–æ–‡ä»¶è·¯å¾„å¹¶åˆ é™¤å®é™…æ–‡ä»¶
            file_path = Path(BASE_DIR / "videoFile" / record['file_path'])
            if file_path.exists():
                try:
                    file_path.unlink()  # åˆ é™¤æ–‡ä»¶
                    print(f"âœ… å®é™…æ–‡ä»¶å·²åˆ é™¤: {file_path}")
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤å®é™…æ–‡ä»¶å¤±è´¥: {e}")
                    # å³ä½¿åˆ é™¤æ–‡ä»¶å¤±è´¥ï¼Œä¹Ÿè¦ç»§ç»­åˆ é™¤æ•°æ®åº“è®°å½•ï¼Œé¿å…æ•°æ®ä¸ä¸€è‡´
            else:
                print(f"âš ï¸ å®é™…æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

            # åˆ é™¤æ•°æ®åº“è®°å½•
            cursor.execute("DELETE FROM file_records WHERE id = ?", (file_id,))
            conn.commit()

        return jsonify({
            "code": 200,
            "msg": "File deleted successfully",
            "data": {
                "id": record['id'],
                "filename": record['filename']
            }
        }), 200

    except Exception as e:
        return jsonify({
            "code": 500,
            "msg": str("delete failed!"),
            "data": None
        }), 500

@app.route('/deleteAccount', methods=['GET'])
def delete_account():
    account_id = int(request.args.get('id'))

    try:
        # è·å–æ•°æ®åº“è¿æ¥
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # æŸ¥è¯¢è¦åˆ é™¤çš„è®°å½•
            cursor.execute("SELECT * FROM user_info WHERE id = ?", (account_id,))
            record = cursor.fetchone()

            if not record:
                return jsonify({
                    "code": 404,
                    "msg": "account not found",
                    "data": None
                }), 404

            record = dict(record)

            # åˆ é™¤æ•°æ®åº“è®°å½•
            cursor.execute("DELETE FROM user_info WHERE id = ?", (account_id,))
            conn.commit()

        return jsonify({
            "code": 200,
            "msg": "account deleted successfully",
            "data": None
        }), 200

    except Exception as e:
        return jsonify({
            "code": 500,
            "msg": str("delete failed!"),
            "data": None
        }), 500

@app.route('/manualConfirmLogin', methods=['POST'])
def manual_confirm_login():
    """æ‰‹åŠ¨ç¡®è®¤ç™»å½•ï¼ˆç”¨äºè§†é¢‘å·ç­‰éœ€è¦æ‰‹åŠ¨ç¡®è®¤çš„å¹³å°ï¼‰"""
    try:
        type = request.args.get('type')  # å¹³å°ç±»å‹ï¼š1 å°çº¢ä¹¦ 2 è§†é¢‘å· 3 æŠ–éŸ³ 4 å¿«æ‰‹
        id = request.args.get('id')  # è´¦å·åç§°
        
        if not type or not id:
            return jsonify({
                "code": 400,
                "msg": "å‚æ•°ä¸å®Œæ•´",
                "data": None
            }), 400
        
        # åªæ”¯æŒè§†é¢‘å·ï¼ˆtype=2ï¼‰
        if type != '2':
            return jsonify({
                "code": 400,
                "msg": "æ‰‹åŠ¨ç¡®è®¤ç™»å½•ä»…æ”¯æŒè§†é¢‘å·",
                "data": None
            }), 400
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡
        if id not in active_browser_contexts:
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ æœªæ‰¾åˆ°ç™»å½•ä¼šè¯: {id}ï¼Œå½“å‰æ´»è·ƒä¼šè¯: {list(active_browser_contexts.keys())}", flush=True)
            return jsonify({
                "code": 404,
                "msg": "æœªæ‰¾åˆ°ç™»å½•ä¼šè¯ï¼Œè¯·é‡æ–°å¼€å§‹ç™»å½•æµç¨‹",
                "data": None
            }), 404
        
        browser_context = active_browser_contexts[id]
        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ‰¾åˆ°æµè§ˆå™¨ä¸Šä¸‹æ–‡: {id}", flush=True)
        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] æµè§ˆå™¨ä¸Šä¸‹æ–‡å†…å®¹: {list(browser_context.keys())}", flush=True)
        
        # å¼‚æ­¥ä¿å­˜Cookieå¹¶éªŒè¯
        import asyncio
        from myUtils.auth import check_cookie
        from pathlib import Path
        import uuid
        
        async def save_and_verify():
            try:
                # ä¼˜å…ˆä½¿ç”¨å·²ä¿å­˜çš„cookiesï¼ˆåœ¨åŒä¸€ä¸ªäº‹ä»¶å¾ªç¯ä¸­è¯»å–çš„ï¼‰
                cookies = browser_context.get('cookies')
                cookies_ready = browser_context.get('cookies_ready', False)
                
                if not cookies_ready or not cookies:
                    return False, "Cookiesæœªå‡†å¤‡å¥½ï¼Œè¯·ç¡®ä¿å·²æ‰«ç ç™»å½•"
                
                # ä¿å­˜Cookieåˆ°æ–‡ä»¶
                uuid_v1 = uuid.uuid1()
                cookies_dir = Path(BASE_DIR / "cookiesFile")
                cookies_dir.mkdir(exist_ok=True)
                cookie_path = cookies_dir / f"{uuid_v1}.json"
                
                # æ‰‹åŠ¨æ„å»º storage_state æ ¼å¼çš„ JSON
                import json
                storage_state = {
                    "cookies": cookies,
                    "origins": []
                }
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                with open(cookie_path, 'w', encoding='utf-8') as f:
                    json.dump(storage_state, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ’¾ Cookieå·²ä¿å­˜åˆ°: {cookie_path}", flush=True)
                
                # éªŒè¯Cookie
                result = await check_cookie(2, f"{uuid_v1}.json")
                if not result:
                    return False, "CookieéªŒè¯å¤±è´¥"
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
                    cursor = conn.cursor()
                    cursor.execute('''
                        INSERT INTO user_info (type, filePath, userName, status)
                        VALUES (?, ?, ?, ?)
                    ''', (2, f"{uuid_v1}.json", id, 1))
                    conn.commit()
                
                # æ¸…ç†æµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆä¸éœ€è¦å…³é—­ï¼Œå› ä¸ºå¯èƒ½è¿˜åœ¨ä½¿ç”¨ä¸­ï¼‰
                # åªä»å­—å…¸ä¸­åˆ é™¤å¼•ç”¨
                pass
                
                if id in active_browser_contexts:
                    del active_browser_contexts[id]
                
                return True, f"{uuid_v1}.json"
            except Exception as e:
                import traceback
                traceback.print_exc()
                return False, str(e)
        
        # è¿è¡Œå¼‚æ­¥å‡½æ•°
        # ä¼˜å…ˆä½¿ç”¨å·²ä¿å­˜çš„cookiesï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•ä»ä¸´æ—¶Cookieæ–‡ä»¶è¯»å–ï¼Œæœ€åå°è¯•ä»æµè§ˆå™¨ä¸Šä¸‹æ–‡ä¸»åŠ¨è·å–
        import json
        cookies = browser_context.get('cookies')
        cookies_ready = browser_context.get('cookies_ready', False)
        temp_cookie_path = browser_context.get('temp_cookie_path')
        
        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] å½“å‰çŠ¶æ€ - cookies_ready: {cookies_ready}, cookiesæ•°é‡: {len(cookies) if cookies else 0}, temp_cookie_path: {temp_cookie_path}", flush=True)
        
        # å¦‚æœcookiesæœªå‡†å¤‡å¥½ï¼Œç­‰å¾…ä¸€å°æ®µæ—¶é—´åé‡è¯•ï¼ˆç»™ç™»å½•æµç¨‹æ—¶é—´ä¿å­˜cookiesï¼‰
        if (not cookies_ready or not cookies) and 'context' in browser_context:
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] â³ Cookiesæœªå‡†å¤‡å¥½ï¼Œç­‰å¾…2ç§’åé‡è¯•...", flush=True)
            import time
            time.sleep(2)
            # é‡æ–°è¯»å–çŠ¶æ€
            cookies = browser_context.get('cookies')
            cookies_ready = browser_context.get('cookies_ready', False)
            temp_cookie_path = browser_context.get('temp_cookie_path')
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] é‡è¯•åçŠ¶æ€ - cookies_ready: {cookies_ready}, cookiesæ•°é‡: {len(cookies) if cookies else 0}", flush=True)
        
        # å¦‚æœcookiesæœªå‡†å¤‡å¥½ï¼Œå°è¯•ä»ä¸´æ—¶Cookieæ–‡ä»¶è¯»å–
        if (not cookies_ready or not cookies) and temp_cookie_path:
            try:
                import os
                from pathlib import Path
                if os.path.exists(temp_cookie_path):
                    with open(temp_cookie_path, 'r', encoding='utf-8') as f:
                        temp_cookie_data = json.load(f)
                        cookies = temp_cookie_data.get('cookies', [])
                        if cookies:
                            cookies_ready = True
                            browser_context['cookies'] = cookies
                            browser_context['cookies_ready'] = True
                            print(f"[+] ä»ä¸´æ—¶Cookieæ–‡ä»¶è¯»å–cookiesæˆåŠŸï¼ˆå…±{len(cookies)}ä¸ªcookiesï¼‰", flush=True)
            except Exception as e:
                print(f"âš ï¸ ä»ä¸´æ—¶Cookieæ–‡ä»¶è¯»å–å¤±è´¥: {e}", flush=True)
        
        # å¦‚æœcookiesä»æœªå‡†å¤‡å¥½ï¼Œå°è¯•ä¸»åŠ¨ä»æµè§ˆå™¨ä¸Šä¸‹æ–‡è¯»å–ï¼ˆè¿™æ˜¯å…³é”®ä¿®å¤ï¼‰
        if (not cookies_ready or not cookies) and 'context' in browser_context:
            try:
                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] ========== å¼€å§‹ä¸»åŠ¨è·å–Cookies ==========", flush=True)
                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤0: æ£€æŸ¥æµè§ˆå™¨ä¸Šä¸‹æ–‡...", flush=True)
                context = browser_context.get('context')
                if context:
                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤0: æµè§ˆå™¨ä¸Šä¸‹æ–‡å­˜åœ¨", flush=True)
                    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æ¥è¿è¡Œå¼‚æ­¥å‡½æ•°
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        # æ­¥éª¤1: å…ˆä¿å­˜storage_stateåˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œç„¶åä»æ–‡ä»¶ä¸­è¯»å–
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤1: å‡†å¤‡ä¸´æ—¶Cookieæ–‡ä»¶è·¯å¾„...", flush=True)
                        if not temp_cookie_path:
                            temp_uuid = uuid.uuid1()
                            cookies_dir = Path(BASE_DIR / "cookiesFile")
                            cookies_dir.mkdir(exist_ok=True)
                            temp_cookie_path = cookies_dir / f"{temp_uuid}.json"
                            browser_context['temp_cookie_path'] = str(temp_cookie_path)
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤1-1: åˆ›å»ºæ–°çš„ä¸´æ—¶Cookieæ–‡ä»¶è·¯å¾„: {temp_cookie_path}", flush=True)
                        else:
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤1-1: ä½¿ç”¨å·²æœ‰ä¸´æ—¶Cookieæ–‡ä»¶è·¯å¾„: {temp_cookie_path}", flush=True)
                        
                        # æ­¥éª¤2: å…ˆä¿å­˜storage_stateï¼ˆåŒ…å«æ‰€æœ‰cookieså’ŒlocalStorageï¼‰
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤2: å¼€å§‹ä¿å­˜storage_stateåˆ°ä¸´æ—¶æ–‡ä»¶...", flush=True)
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    ç›®æ ‡æ–‡ä»¶: {temp_cookie_path}", flush=True)
                        loop.run_until_complete(context.storage_state(path=str(temp_cookie_path)))
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤2: storage_stateå·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶", flush=True)
                        
                        # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸä¿å­˜
                        if temp_cookie_path.exists():
                            file_size = temp_cookie_path.stat().st_size
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚", flush=True)
                        else:
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âš ï¸ æ­¥éª¤2: è­¦å‘Š - æ–‡ä»¶ä¿å­˜åä¸å­˜åœ¨ï¼", flush=True)
                        
                        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
                        import time
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] ç­‰å¾…0.5ç§’ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ...", flush=True)
                        time.sleep(0.5)
                        
                        # æ­¥éª¤3: ä»æ–‡ä»¶ä¸­è¯»å–cookies
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤3: å¼€å§‹ä»storage_stateæ–‡ä»¶è¯»å–cookies...", flush=True)
                        cookies_from_file = []
                        storage_data = None
                        if temp_cookie_path.exists():
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    æ–‡ä»¶å­˜åœ¨ï¼Œå¼€å§‹è¯»å–...", flush=True)
                            with open(temp_cookie_path, 'r', encoding='utf-8') as f:
                                storage_data = json.load(f)
                                cookies_from_file = storage_data.get('cookies', [])
                                origins_data = storage_data.get('origins', [])
                                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    æ–‡ä»¶å†…å®¹ - cookiesæ•°é‡: {len(cookies_from_file)}, originsæ•°é‡: {len(origins_data)}", flush=True)
                                
                                if cookies_from_file and len(cookies_from_file) > 0:
                                    cookies = cookies_from_file
                                    cookies_ready = True
                                    browser_context['cookies'] = cookies
                                    browser_context['cookies_ready'] = True
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤3: ä»storage_stateæ–‡ä»¶è¯»å–cookiesæˆåŠŸï¼", flush=True)
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    Cookieæ•°é‡: {len(cookies)}", flush=True)
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    å‰3ä¸ªCookieåç§°: {[c.get('name', 'N/A') for c in cookies[:3]]}", flush=True)
                                else:
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âš ï¸ æ­¥éª¤3: æ–‡ä»¶ä¸­cookiesæ•°ç»„ä¸ºç©º", flush=True)
                                    if origins_data and len(origins_data) > 0:
                                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    ä½†å‘ç° {len(origins_data)} ä¸ªoriginsæ•°æ®ï¼ˆå¯èƒ½åŒ…å«localStorageï¼‰", flush=True)
                        else:
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ æ­¥éª¤3: ä¸´æ—¶Cookieæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è¯»å–", flush=True)
                        
                        # æ­¥éª¤4: å¦‚æœæ–‡ä»¶ä¸­æ²¡æœ‰cookiesï¼Œå°è¯•ç›´æ¥ä»contextè¯»å–
                        if not cookies or len(cookies) == 0:
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤4: æ–‡ä»¶ä¸­cookiesä¸ºç©ºï¼Œå°è¯•ç›´æ¥ä»context.cookies()è¯»å–...", flush=True)
                            try:
                                cookies_from_context = loop.run_until_complete(context.cookies())
                                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    context.cookies()è¿”å›ç»“æœ: {len(cookies_from_context) if cookies_from_context else 0} ä¸ªcookies", flush=True)
                                
                                if cookies_from_context and len(cookies_from_context) > 0:
                                    cookies = cookies_from_context
                                    cookies_ready = True
                                    browser_context['cookies'] = cookies
                                    browser_context['cookies_ready'] = True
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤4: ä»æµè§ˆå™¨ä¸Šä¸‹æ–‡è¯»å–cookiesæˆåŠŸï¼", flush=True)
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    Cookieæ•°é‡: {len(cookies)}", flush=True)
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    å‰3ä¸ªCookieåç§°: {[c.get('name', 'N/A') for c in cookies[:3]]}", flush=True)
                                    
                                    # æ›´æ–°ä¸´æ—¶æ–‡ä»¶
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤4-1: æ›´æ–°ä¸´æ—¶Cookieæ–‡ä»¶...", flush=True)
                                    if storage_data is None:
                                        storage_data = {}
                                    storage_data['cookies'] = cookies
                                    if 'origins' not in storage_data:
                                        storage_data['origins'] = []
                                    
                                    with open(temp_cookie_path, 'w', encoding='utf-8') as f:
                                        json.dump(storage_data, f, ensure_ascii=False, indent=2)
                                    
                                    updated_file_size = temp_cookie_path.stat().st_size
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤4-1: ä¸´æ—¶Cookieæ–‡ä»¶å·²æ›´æ–°", flush=True)
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    æ›´æ–°åæ–‡ä»¶å¤§å°: {updated_file_size} å­—èŠ‚", flush=True)
                                else:
                                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ æ­¥éª¤4: context.cookies()è¿”å›çš„cookiesä¹Ÿä¸ºç©º", flush=True)
                            except Exception as context_error:
                                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ æ­¥éª¤4: ä»contextè¯»å–cookieså¤±è´¥: {context_error}", flush=True)
                                import traceback
                                traceback.print_exc()
                        
                        # æœ€ç»ˆæ£€æŸ¥
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] ========== Cookiesè·å–ç»“æœ ==========", flush=True)
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    cookies_ready: {cookies_ready}", flush=True)
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    cookiesæ•°é‡: {len(cookies) if cookies else 0}", flush=True)
                        if cookies and len(cookies) > 0:
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æˆåŠŸè·å–åˆ°Cookiesï¼", flush=True)
                        else:
                            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ æœªèƒ½è·å–åˆ°Cookies", flush=True)
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] ========================================", flush=True)
                    finally:
                        loop.close()
                else:
                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âš ï¸ æ­¥éª¤0: æµè§ˆå™¨ä¸Šä¸‹æ–‡ä¸­çš„contextä¸ºNone", flush=True)
            except Exception as e:
                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ ä¸»åŠ¨ä»æµè§ˆå™¨ä¸Šä¸‹æ–‡è¯»å–cookieså¤±è´¥: {e}", flush=True)
                import traceback
                traceback.print_exc()
        elif (not cookies_ready or not cookies) and 'context' not in browser_context:
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âš ï¸ æµè§ˆå™¨ä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰contextå¯¹è±¡ï¼Œæ— æ³•ä¸»åŠ¨è¯»å–cookies", flush=True)
        
        if not cookies_ready or not cookies:
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ Cookiesæœªå‡†å¤‡å¥½ - cookies_ready: {cookies_ready}, cookies: {len(cookies) if cookies else 0}", flush=True)
            return jsonify({
                "code": 500,
                "msg": "Cookiesæœªå‡†å¤‡å¥½ï¼Œè¯·ç¡®ä¿å·²æ‰«ç ç™»å½•",
                "data": None
            }), 500
        
        try:
            # ä¿å­˜Cookieåˆ°æ–‡ä»¶
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] ========== å¼€å§‹ä¿å­˜Cookieåˆ°æœ€ç»ˆæ–‡ä»¶ ==========", flush=True)
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤5: ç”ŸæˆUUIDå’Œæ–‡ä»¶è·¯å¾„...", flush=True)
            uuid_v1 = uuid.uuid1()
            cookies_dir = Path(BASE_DIR / "cookiesFile")
            cookies_dir.mkdir(exist_ok=True)
            cookie_path = cookies_dir / f"{uuid_v1}.json"
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤5: UUIDç”ŸæˆæˆåŠŸ: {uuid_v1}", flush=True)
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤5: Cookieæ–‡ä»¶è·¯å¾„: {cookie_path}", flush=True)
            
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤6: å‡†å¤‡Cookieæ•°æ®...", flush=True)
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    è´¦å·: {id}", flush=True)
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    Cookieæ•°é‡: {len(cookies) if cookies else 0}", flush=True)
            if cookies and len(cookies) > 0:
                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    å‰5ä¸ªCookieåç§°: {[c.get('name', 'N/A') for c in cookies[:5]]}", flush=True)
                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    CookieåŸŸååˆ—è¡¨: {list(set([c.get('domain', 'N/A') for c in cookies[:10]]))}", flush=True)
            
            # æ‰‹åŠ¨æ„å»º storage_state æ ¼å¼çš„ JSON
            storage_state = {
                "cookies": cookies,
                "origins": []
            }
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤6: Cookieæ•°æ®å‡†å¤‡å®Œæˆ", flush=True)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] [+] æ­¥éª¤7: å¼€å§‹å†™å…¥Cookieæ–‡ä»¶...", flush=True)
            with open(cookie_path, 'w', encoding='utf-8') as f:
                json.dump(storage_state, f, ensure_ascii=False, indent=2)
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸä¿å­˜
            if cookie_path.exists():
                file_size = cookie_path.stat().st_size
                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… æ­¥éª¤7: Cookieæ–‡ä»¶å†™å…¥æˆåŠŸ", flush=True)
                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚", flush=True)
                
                # éªŒè¯æ–‡ä»¶å†…å®¹
                with open(cookie_path, 'r', encoding='utf-8') as f:
                    saved_data = json.load(f)
                    saved_cookies_count = len(saved_data.get('cookies', []))
                    print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•]    éªŒè¯: æ–‡ä»¶ä¸­åŒ…å« {saved_cookies_count} ä¸ªcookies", flush=True)
                    if saved_cookies_count != len(cookies):
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âš ï¸ è­¦å‘Š: ä¿å­˜çš„Cookieæ•°é‡({saved_cookies_count})ä¸åŸå§‹æ•°é‡({len(cookies) if cookies else 0})ä¸ä¸€è‡´", flush=True)
                    else:
                        print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… éªŒè¯é€šè¿‡: Cookieæ•°é‡ä¸€è‡´", flush=True)
            else:
                print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ æ­¥éª¤7: Cookieæ–‡ä»¶å†™å…¥å¤±è´¥ - æ–‡ä»¶ä¸å­˜åœ¨ï¼", flush=True)
            
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] ========== Cookieæ–‡ä»¶ä¿å­˜å®Œæˆ ==========", flush=True)
            
            # éªŒè¯Cookieï¼ˆä½¿ç”¨å¼‚æ­¥æ–¹å¼ï¼Œä½†åŒæ­¥è°ƒç”¨ï¼‰
            from myUtils.auth import check_cookie
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(check_cookie(2, f"{uuid_v1}.json"))
            finally:
                loop.close()
            
            if not result:
                return jsonify({
                    "code": 500,
                    "msg": "CookieéªŒè¯å¤±è´¥",
                    "data": None
                }), 500
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO user_info (type, filePath, userName, status)
                    VALUES (?, ?, ?, ?)
                ''', (2, f"{uuid_v1}.json", id, 1))
                conn.commit()
            
            # æ¸…ç†æµè§ˆå™¨ä¸Šä¸‹æ–‡
            if id in active_browser_contexts:
                del active_browser_contexts[id]
            
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âœ… ç™»å½•ç¡®è®¤æˆåŠŸ - æ¥å£: /manualConfirmLogin (POST)", flush=True)
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] ğŸ“¤ è¿”å›Cookieæ•°æ® - è´¦å·: {id}, Cookieæ–‡ä»¶è·¯å¾„: {uuid_v1}.json, Cookieæ•°é‡: {len(cookies) if cookies else 0}", flush=True)
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] è¿”å›JSONæ•°æ®: {{'code': 200, 'msg': 'ç™»å½•ç¡®è®¤æˆåŠŸ', 'data': {{'filePath': '{uuid_v1}.json'}}}}", flush=True)
            
            return jsonify({
                "code": 200,
                "msg": "ç™»å½•ç¡®è®¤æˆåŠŸ",
                "data": {
                    "filePath": f"{uuid_v1}.json"
                }
            }), 200
            
        except Exception as e:
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] âŒ æ‰‹åŠ¨ç¡®è®¤ç™»å½•å¤±è´¥: {str(e)}", flush=True)
            import traceback
            error_trace = traceback.format_exc()
            print(f"[æ‰‹åŠ¨ç¡®è®¤ç™»å½•] é”™è¯¯å †æ ˆ:\n{error_trace}", flush=True)
            return jsonify({
                "code": 500,
                "msg": f"ç™»å½•ç¡®è®¤å¤±è´¥: {str(e)}",
                "data": None
            }), 500
            return jsonify({
                "code": 200,
                "msg": "ç™»å½•ç¡®è®¤æˆåŠŸ",
                "data": {
                    "filePath": result
                }
            }), 200
        else:
            return jsonify({
                "code": 500,
                "msg": f"ç™»å½•ç¡®è®¤å¤±è´¥: {result}",
                "data": None
            }), 500
            
    except Exception as e:
        print(f"âŒ æ‰‹åŠ¨ç¡®è®¤ç™»å½•å¤±è´¥: {str(e)}", flush=True)
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"ç™»å½•ç¡®è®¤å¤±è´¥: {str(e)}",
            "data": None
        }), 500

@app.route('/addAccountDirect', methods=['POST'])
def add_account_direct():
    """ç›´æ¥åˆ›å»ºè´¦å·ï¼ˆä¸é€šè¿‡ç™»å½•æµç¨‹ï¼Œç”¨äºæœ¬åœ°ä¸Šä¼ Cookieï¼‰"""
    try:
        data = request.get_json(silent=True) or {}
        type = data.get('type')  # å¹³å°ç±»å‹ï¼š1 å°çº¢ä¹¦ 2 è§†é¢‘å· 3 æŠ–éŸ³ 4 å¿«æ‰‹
        userName = data.get('userName', '').strip()
        platform = data.get('platform', '')  # å¹³å°åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        if not type:
            return jsonify({
                "code": 400,
                "msg": "å¹³å°ç±»å‹ä¸èƒ½ä¸ºç©º",
                "data": None
            }), 400

        if not userName:
            return jsonify({
                "code": 400,
                "msg": "è´¦å·åç§°ä¸èƒ½ä¸ºç©º",
                "data": None
            }), 400

        # æ£€æŸ¥è´¦å·æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ ¹æ®ç”¨æˆ·åå’Œå¹³å°ç±»å‹ï¼‰
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT id FROM user_info WHERE userName = ? AND type = ?', (userName, type))
            existing = cursor.fetchone()
            
            if existing:
                return jsonify({
                    "code": 400,
                    "msg": "è¯¥è´¦å·å·²å­˜åœ¨",
                    "data": None
                }), 400

            # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦æ–‡ä»¶è·¯å¾„ï¼ˆç”¨æˆ·åç»­å¯ä»¥ä¸Šä¼ Cookieæ–‡ä»¶ï¼‰
            import uuid
            uuid_v1 = uuid.uuid1()
            filePath = f"{uuid_v1}.json"
            
            # æ’å…¥è´¦å·è®°å½•ï¼Œstatusè®¾ä¸º0ï¼ˆå¼‚å¸¸çŠ¶æ€ï¼Œå› ä¸ºè¿˜æ²¡æœ‰Cookieï¼‰
            cursor.execute('''
                INSERT INTO user_info (type, filePath, userName, status)
                VALUES (?, ?, ?, ?)
            ''', (type, filePath, userName, 0))
            conn.commit()
            
            # è·å–æ–°åˆ›å»ºçš„è´¦å·ID
            account_id = cursor.lastrowid
            
            print(f"âœ… ç›´æ¥åˆ›å»ºè´¦å·æˆåŠŸ - å¹³å°: {platform}, è´¦å·åç§°: {userName}, ID: {account_id}")

        return jsonify({
            "code": 200,
            "msg": "è´¦å·åˆ›å»ºæˆåŠŸï¼Œè¯·åç»­ä¸Šä¼ Cookieæ–‡ä»¶",
            "data": {
                "id": account_id,
                "userName": userName,
                "type": type,
                "filePath": filePath
            }
        }), 200

    except Exception as e:
        print(f"âŒ ç›´æ¥åˆ›å»ºè´¦å·å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"åˆ›å»ºè´¦å·å¤±è´¥: {str(e)}",
            "data": None
        }), 500


# SSE ç™»å½•æ¥å£
@app.route('/login')
def login():
    # 1 å°çº¢ä¹¦ 2 è§†é¢‘å· 3 æŠ–éŸ³ 4 å¿«æ‰‹
    type = request.args.get('type')
    # è´¦å·å
    id = request.args.get('id')
    # è‡ªåŠ¨åŒ–æ¡†æ¶é€‰æ‹©ï¼ˆä»…è§†é¢‘å·ä½¿ç”¨ï¼‰
    automation_tool = request.args.get('automation_tool', 'playwright')
    
    print(f"\n[ç™»å½•API] æ”¶åˆ°ç™»å½•è¯·æ±‚ - å¹³å°ç±»å‹: {type}, è´¦å·åç§°: {id}, è‡ªåŠ¨åŒ–æ¡†æ¶: {automation_tool}", flush=True)
    print(f"[ç™»å½•API] è´¦å·åç§°å‚æ•°å€¼: {repr(id)}", flush=True)  # ä½¿ç”¨repræ˜¾ç¤ºåŸå§‹å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬ç‰¹æ®Šå­—ç¬¦

    # å¦‚æœè¯¥è´¦å·å·²æœ‰æ­£åœ¨è¿›è¡Œçš„ç™»å½•è¯·æ±‚ï¼Œå…ˆæ¸…ç†æ—§çš„é˜Ÿåˆ—
    if id in active_queues:
        print(f"[ç™»å½•API] è­¦å‘Šï¼šè´¦å· {id} å·²æœ‰æ­£åœ¨è¿›è¡Œçš„ç™»å½•è¯·æ±‚ï¼Œå°†æ¸…ç†æ—§é˜Ÿåˆ—")
        old_queue = active_queues[id]
        # å°è¯•æ¸…ç©ºæ—§é˜Ÿåˆ—
        while not old_queue.empty():
            try:
                old_queue.get_nowait()
            except:
                pass

    # æ¨¡æ‹Ÿä¸€ä¸ªç”¨äºå¼‚æ­¥é€šä¿¡çš„é˜Ÿåˆ—
    status_queue = Queue()
    active_queues[id] = status_queue
    print(f"[ç™»å½•API] å·²åˆ›å»ºæ–°é˜Ÿåˆ—ï¼Œå½“å‰æ´»è·ƒé˜Ÿåˆ—æ•°: {len(active_queues)}", flush=True)

    # å¦‚æœæ˜¯è§†é¢‘å·ç™»å½•ï¼Œåˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡å­˜å‚¨
    browser_context_storage = None
    if type == '2':  # è§†é¢‘å·
        browser_context_storage = {}
        active_browser_contexts[id] = browser_context_storage
        print(f"[ç™»å½•API] å·²åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡å­˜å‚¨: {id}", flush=True)

    def on_close():
        print(f"[ç™»å½•API] æ¸…ç†é˜Ÿåˆ—: {id}")
        if id in active_queues:
            del active_queues[id]
        # æ¸…ç†æµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆå»¶è¿Ÿæ¸…ç†ï¼Œç»™æ‰‹åŠ¨ç¡®è®¤ç•™æ—¶é—´ï¼‰
        if id in active_browser_contexts:
            # å»¶è¿Ÿ30ç§’æ¸…ç†ï¼Œç»™æ‰‹åŠ¨ç¡®è®¤ç•™æ—¶é—´
            def delayed_cleanup():
                import time
                time.sleep(30)
                if id in active_browser_contexts:
                    # å°è¯•å…³é—­æµè§ˆå™¨
                    try:
                        ctx = active_browser_contexts[id]
                        if 'browser' in ctx and ctx['browser']:
                            pass  # æµè§ˆå™¨ä¼šåœ¨ç™»å½•æµç¨‹ä¸­å…³é—­
                    except:
                        pass
                    del active_browser_contexts[id]
                    print(f"[ç™»å½•API] å·²æ¸…ç†æµè§ˆå™¨ä¸Šä¸‹æ–‡: {id}", flush=True)
            threading.Thread(target=delayed_cleanup, daemon=True).start()
    
    # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡çº¿ç¨‹
    print(f"[ç™»å½•API] å¯åŠ¨ç™»å½•çº¿ç¨‹ï¼Œä¼ é€’å‚æ•° - type: {type}, id: {repr(id)}, automation_tool: {automation_tool}", flush=True)
    print(f"[ç™»å½•API] Cookieå°†é€šè¿‡SSEæµè¿”å› - æ¥å£: /login (SSEæµ)", flush=True)
    thread = threading.Thread(target=run_async_function, args=(type,id,status_queue,browser_context_storage,automation_tool), daemon=True)
    thread.start()
    response = Response(sse_stream(status_queue,), mimetype='text/event-stream')
    response.headers['Cache-Control'] = 'no-cache'
    response.headers['X-Accel-Buffering'] = 'no'  # å…³é”®ï¼šç¦ç”¨ Nginx ç¼“å†²
    response.headers['Content-Type'] = 'text/event-stream; charset=utf-8'
    response.headers['Connection'] = 'keep-alive'
    response.headers['Access-Control-Allow-Origin'] = '*'  # ç¡®ä¿CORSæ”¯æŒ
    response.headers['Access-Control-Allow-Headers'] = 'Cache-Control'
    return response

def download_video_from_url(url, output_dir=None, max_retries=3):
    """
    ä»URLä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    Args:
        url: è§†é¢‘URLï¼ˆå¦‚è°·æ­Œäº‘å­˜å‚¨é“¾æ¥ï¼‰
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º videoFile ç›®å½•
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤3æ¬¡
    Returns:
        ä¸‹è½½åçš„æœ¬åœ°æ–‡ä»¶åï¼ˆç›¸å¯¹äºvideoFileç›®å½•ï¼‰
    """
    if output_dir is None:
        output_dir = Path(BASE_DIR / "videoFile")
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä»URLä¸­æå–æ–‡ä»¶å
    parsed_url = urlparse(url)
    url_filename = os.path.basename(parsed_url.path)
    # å¦‚æœURLä¸­æ²¡æœ‰æ–‡ä»¶åï¼Œä½¿ç”¨UUIDç”Ÿæˆ
    if not url_filename or '.' not in url_filename:
        url_filename = f"downloaded_{uuid.uuid1()}.mp4"
    # å»æ‰æŸ¥è¯¢å‚æ•°
    if '?' in url_filename:
        url_filename = url_filename.split('?')[0]
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    uuid_v1 = uuid.uuid1()
    local_filename = f"{uuid_v1}_{url_filename}"
    local_filepath = output_dir / local_filename
        
    # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': '*/*',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Cache-Control': 'no-cache',
        'Range': 'bytes=0-',  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
    }
    
    # é‡è¯•æœºåˆ¶
    for attempt in range(max_retries):
        try:
            print(f"ğŸ“¥ å¼€å§‹ä»URLä¸‹è½½è§†é¢‘ (å°è¯• {attempt + 1}/{max_retries}): {url}")
            
            # åˆ›å»ºä¼šè¯ä»¥ä¿æŒè¿æ¥ï¼Œé…ç½®é‡è¯•å’Œè¿æ¥æ± 
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry
            import urllib3
            
            # ç¦ç”¨ SSL è­¦å‘Šï¼ˆå› ä¸ºå›½å†…æœåŠ¡å™¨è®¿é—® Google æœåŠ¡å¯èƒ½éœ€è¦ç¦ç”¨ SSL éªŒè¯ï¼‰
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
            
            session = requests.Session()
            session.headers.update(headers)
            
            # é…ç½®ä»£ç†ï¼ˆç”¨äºè®¿é—® Google æœåŠ¡ï¼‰
            proxies = {}
            if HTTP_PROXY or HTTPS_PROXY:
                if HTTP_PROXY:
                    proxies['http'] = HTTP_PROXY
                if HTTPS_PROXY:
                    proxies['https'] = HTTPS_PROXY
                elif HTTP_PROXY:
                    # å¦‚æœåªè®¾ç½®äº† HTTP_PROXYï¼ŒHTTPS ä¹Ÿä½¿ç”¨å®ƒ
                    proxies['https'] = HTTP_PROXY
                if proxies:
                    print(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxies}")
                    session.proxies = proxies
            else:
                print("âš ï¸ æœªé…ç½®ä»£ç†ï¼Œå°†å°è¯•ç›´æ¥è¿æ¥ï¼ˆå¯èƒ½å¤±è´¥ï¼‰")
            
            # é…ç½®é‡è¯•ç­–ç•¥
            retry_strategy = Retry(
                total=3,
                backoff_factor=1,
                status_forcelist=[429, 500, 502, 503, 504],
                allowed_methods=["GET", "HEAD"]
            )
            adapter = HTTPAdapter(
                max_retries=retry_strategy,
                pool_connections=10,
                pool_maxsize=10
            )
            session.mount("http://", adapter)
            session.mount("https://", adapter)
            
            # ä¸‹è½½æ–‡ä»¶ï¼ˆå¢åŠ è¶…æ—¶æ—¶é—´ï¼Œä½¿ç”¨è¿æ¥æ± ï¼‰
            print(f"ğŸ“¥ ä¸‹è½½ä¸­: {url} -> {local_filepath}")
            
            # å¯¹äº Google Cloud Storage æˆ–å›½å†…æœåŠ¡å™¨ï¼Œé»˜è®¤ç¦ç”¨ SSL éªŒè¯
            # å› ä¸ºå›½å†…æœåŠ¡å™¨è®¿é—® Google æœåŠ¡ç»å¸¸é‡åˆ° SSL/ç½‘ç»œé—®é¢˜
            verify_ssl = False  # é»˜è®¤ç¦ç”¨ SSL éªŒè¯ï¼Œé¿å…ç½‘ç»œé—®é¢˜
            if 'storage.googleapis.com' in url or 'googleapis.com' in url:
                print("âš ï¸ æ£€æµ‹åˆ° Google Cloud Storage URLï¼Œä½¿ç”¨ç¦ç”¨ SSL éªŒè¯æ¨¡å¼ï¼ˆå›½å†…æœåŠ¡å™¨è®¿é—®éœ€è¦ï¼‰")
                verify_ssl = False
            
            response = session.get(
                url, 
                stream=True, 
                timeout=(60, 900),  # (è¿æ¥è¶…æ—¶60ç§’, è¯»å–è¶…æ—¶900ç§’=15åˆ†é’Ÿ)
                allow_redirects=True,
                verify=verify_ssl
            )
            response.raise_for_status()
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('content-length', 0))
            if total_size > 0:
                print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {total_size / (1024*1024):.2f} MB")
            
            # å†™å…¥æ–‡ä»¶ï¼ˆä½¿ç”¨æ›´å¤§çš„chunk sizeä»¥æé«˜ä¸‹è½½é€Ÿåº¦ï¼‰
            downloaded_size = 0
            chunk_size = 64 * 1024  # 64KB chunks
            
            with open(local_filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        if total_size > 0:
                            progress = (downloaded_size / total_size) * 100
                            # æ¯10MBæ‰“å°ä¸€æ¬¡è¿›åº¦
                            if downloaded_size % (10 * 1024 * 1024) < chunk_size:
                                print(f"ğŸ“¥ ä¸‹è½½è¿›åº¦: {progress:.1f}% ({downloaded_size / (1024*1024):.2f} MB / {total_size / (1024*1024):.2f} MB)")
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦å®Œæ•´ä¸‹è½½
            if total_size > 0 and downloaded_size != total_size:
                raise Exception(f"æ–‡ä»¶ä¸‹è½½ä¸å®Œæ•´: å·²ä¸‹è½½ {downloaded_size} å­—èŠ‚ï¼ŒæœŸæœ› {total_size} å­—èŠ‚")
            
            print(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {local_filename} ({downloaded_size / (1024*1024):.2f} MB)")
            session.close()
            return local_filename
            
        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout, 
                ConnectionResetError, requests.exceptions.ChunkedEncodingError,
                requests.exceptions.SSLError) as e:
            # è¿æ¥ç›¸å…³é”™è¯¯ï¼Œå¯ä»¥é‡è¯•
            error_msg = str(e)
            error_type = type(e).__name__
            print(f"âš ï¸ ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {error_type}: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ ProtocolErrorï¼ˆæ¥è‡ª urllib3ï¼‰
            is_protocol_error = 'ProtocolError' in error_msg or '10054' in error_msg or 'ConnectionResetError' in error_msg
            
            # å¦‚æœæ˜¯ SSL é”™è¯¯æˆ–åè®®é”™è¯¯ï¼Œæœ€åä¸€æ¬¡å°è¯•æ—¶ç¦ç”¨ SSL éªŒè¯
            if attempt == max_retries - 1 and (is_protocol_error or 'SSL' in error_msg or 'ssl' in error_msg.lower()):
                print(f"ğŸ”„ æœ€åä¸€æ¬¡å°è¯•ï¼šç¦ç”¨ SSL éªŒè¯...")
                try:
                    # ç¦ç”¨ SSL è­¦å‘Š
                    import urllib3
                    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
                    
                    session = requests.Session()
                    session.headers.update(headers)
                    # é…ç½®ä»£ç†ï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
                    proxies = {}
                    if HTTP_PROXY or HTTPS_PROXY:
                        if HTTP_PROXY:
                            proxies['http'] = HTTP_PROXY
                        if HTTPS_PROXY:
                            proxies['https'] = HTTPS_PROXY
                        elif HTTP_PROXY:
                            proxies['https'] = HTTP_PROXY
                    if proxies:
                        session.proxies = proxies
                    response = session.get(
                        url, 
                        stream=True, 
                        timeout=(60, 900),
                        allow_redirects=True,
                        verify=False  # ç¦ç”¨ SSL éªŒè¯ï¼ˆä»…ä½œä¸ºæœ€åæ‰‹æ®µï¼‰
                    )
                    response.raise_for_status()
                    
                    # ç»§ç»­ä¸‹è½½æµç¨‹
                    total_size = int(response.headers.get('content-length', 0))
                    if total_size > 0:
                        print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {total_size / (1024*1024):.2f} MB")
                    
                    downloaded_size = 0
                    chunk_size = 64 * 1024
                    with open(local_filepath, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=chunk_size):
                            if chunk:
                                f.write(chunk)
                                downloaded_size += len(chunk)
                    
                    if total_size > 0 and downloaded_size != total_size:
                        raise Exception(f"æ–‡ä»¶ä¸‹è½½ä¸å®Œæ•´: å·²ä¸‹è½½ {downloaded_size} å­—èŠ‚ï¼ŒæœŸæœ› {total_size} å­—èŠ‚")
                    
                    print(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {local_filename} ({downloaded_size / (1024*1024):.2f} MB)")
                    session.close()
                    return local_filename
                except Exception as ssl_e:
                    print(f"âŒ å³ä½¿ç¦ç”¨ SSL éªŒè¯ä¹Ÿå¤±è´¥: {str(ssl_e)}")
            
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 3  # é€’å¢ç­‰å¾…æ—¶é—´ï¼š3ç§’ã€6ç§’ã€9ç§’
                print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                import time
                time.sleep(wait_time)
                # å¦‚æœæ–‡ä»¶å·²éƒ¨åˆ†ä¸‹è½½ï¼Œåˆ é™¤å®ƒä»¥ä¾¿é‡æ–°ä¸‹è½½
                if local_filepath.exists():
                    try:
                        local_filepath.unlink()
                        print(f"ğŸ—‘ï¸ å·²åˆ é™¤ä¸å®Œæ•´çš„æ–‡ä»¶: {local_filename}")
                    except:
                        pass
                continue
            else:
                # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥äº†
                print(f"âŒ ä¸‹è½½è§†é¢‘å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {str(e)}")
                import traceback
                traceback.print_exc()
                raise Exception(f"ä»URLä¸‹è½½è§†é¢‘å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {str(e)}")
        
        except Exception as e:
            # å…¶ä»–é”™è¯¯ï¼Œä¸é‡è¯•
            print(f"âŒ ä¸‹è½½è§†é¢‘å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # æ¸…ç†ä¸å®Œæ•´çš„æ–‡ä»¶
            if local_filepath.exists():
                try:
                    local_filepath.unlink()
                except:
                    pass
        raise Exception(f"ä»URLä¸‹è½½è§†é¢‘å¤±è´¥: {str(e)}")


def download_google_storage_file(file_path_or_name, output_dir=None):
    """
    ä»è°·æ­Œå­˜å‚¨ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°
    Args:
        file_path_or_name: æ–‡ä»¶åæˆ–file_pathï¼ˆä»æ•°æ®åº“ä¸­æŸ¥è¯¢ï¼‰
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º videoFile ç›®å½•
    Returns:
        ä¸‹è½½åçš„æœ¬åœ°æ–‡ä»¶åï¼ˆç›¸å¯¹äºvideoFileç›®å½•ï¼‰ï¼Œå¦‚æœæ–‡ä»¶ä¸æ˜¯è°·æ­Œå­˜å‚¨æˆ–å·²å­˜åœ¨æœ¬åœ°ï¼Œè¿”å›åŸæ–‡ä»¶å
    """
    if output_dir is None:
        output_dir = Path(BASE_DIR / "videoFile")
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # æŸ¥è¯¢æ•°æ®åº“ï¼Œåˆ¤æ–­æ–‡ä»¶æ˜¯å¦æ¥è‡ªè°·æ­Œå­˜å‚¨
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # å°è¯•é€šè¿‡file_pathæŸ¥è¯¢
            cursor.execute('''
                SELECT source, uri, file_path, filename 
                FROM file_records 
                WHERE file_path = ? OR filename = ?
                LIMIT 1
            ''', (file_path_or_name, file_path_or_name))
            
            row = cursor.fetchone()
            
            if not row:
                # æ–‡ä»¶ä¸åœ¨æ•°æ®åº“ä¸­ï¼Œæ£€æŸ¥æœ¬åœ°æ˜¯å¦å­˜åœ¨ï¼ˆå°è¯•å¤šä¸ªç›®å½•ï¼‰
                possible_paths = [
                    output_dir / file_path_or_name,  # videoFile ç›®å½•
                    Path(BASE_DIR / "media" / file_path_or_name),  # media ç›®å½•
                    Path(BASE_DIR / file_path_or_name),  # æ ¹ç›®å½•
                ]
                
                for possible_path in possible_paths:
                    if possible_path.exists():
                        print(f"âœ… æ–‡ä»¶ä¸åœ¨æ•°æ®åº“ä¸­ï¼Œä½†æœ¬åœ°æ–‡ä»¶å­˜åœ¨: {possible_path}")
                        # å¦‚æœæ–‡ä»¶ä¸åœ¨ videoFile ç›®å½•ï¼Œå¤åˆ¶è¿‡å»
                        if possible_path.parent != output_dir:
                            import shutil
                            target_path = output_dir / file_path_or_name
                            shutil.copy2(possible_path, target_path)
                            print(f"âœ… æ–‡ä»¶å·²å¤åˆ¶åˆ° videoFile ç›®å½•: {target_path}")
                        return file_path_or_name
                
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆæ•°æ®åº“å’Œæœ¬åœ°éƒ½æ²¡æœ‰ï¼‰: {file_path_or_name} (å·²å°è¯•: videoFile, media, æ ¹ç›®å½•)")
            
            source = row['source'] if row else None
            uri = row['uri'] if row else None
            
            # å¦‚æœä¸æ˜¯è°·æ­Œå­˜å‚¨æ–‡ä»¶ï¼Œæ£€æŸ¥æœ¬åœ°æ˜¯å¦å­˜åœ¨
            if source != 'è°·æ­Œå­˜å‚¨ä¸Šä¼ ':
                # å°è¯•å¤šä¸ªå¯èƒ½çš„ç›®å½•
                possible_paths = [
                    output_dir / file_path_or_name,  # videoFile ç›®å½•
                    Path(BASE_DIR / "media" / file_path_or_name),  # media ç›®å½•
                    Path(BASE_DIR / file_path_or_name),  # æ ¹ç›®å½•
                ]
                
                for possible_path in possible_paths:
                    if possible_path.exists():
                        print(f"âœ… æ–‡ä»¶å·²å­˜åœ¨äºæœ¬åœ°: {possible_path}")
                        # è¿”å›ç›¸å¯¹äº videoFile ç›®å½•çš„æ–‡ä»¶å
                        if possible_path.parent == output_dir:
                            return file_path_or_name
                        else:
                            # å¦‚æœæ–‡ä»¶åœ¨å…¶ä»–ç›®å½•ï¼Œéœ€è¦å¤åˆ¶åˆ° videoFile ç›®å½•
                            import shutil
                            target_path = output_dir / file_path_or_name
                            shutil.copy2(possible_path, target_path)
                            print(f"âœ… æ–‡ä»¶å·²å¤åˆ¶åˆ° videoFile ç›®å½•: {target_path}")
                            return file_path_or_name
                
                raise FileNotFoundError(f"æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {file_path_or_name} (å·²å°è¯•: videoFile, media, æ ¹ç›®å½•)")
            
            # å¦‚æœæ˜¯è°·æ­Œå­˜å‚¨æ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡
            local_filepath = output_dir / file_path_or_name
            if local_filepath.exists():
                print(f"âœ… è°·æ­Œå­˜å‚¨æ–‡ä»¶å·²å­˜åœ¨æœ¬åœ°: {file_path_or_name}")
                return file_path_or_name
            
            # éœ€è¦ä»è°·æ­Œå­˜å‚¨ä¸‹è½½
            if not uri:
                raise Exception(f"è°·æ­Œå­˜å‚¨æ–‡ä»¶ç¼ºå°‘URI: {file_path_or_name}")
            
            print(f"ğŸ“¥ å¼€å§‹ä»è°·æ­Œå­˜å‚¨ä¸‹è½½æ–‡ä»¶: {file_path_or_name}")
            print(f"ğŸ“‹ URI: {uri}")
            
            # ä»URIä¸­æå–æ–‡ä»¶ID
            # URIæ ¼å¼: https://generativelanguage.googleapis.com/v1beta/files/8kxw2l3kmzkh
            # æˆ–è€…: files/8kxw2l3kmzkh
            file_id = None
            if '/files/' in uri:
                file_id = uri.split('/files/')[-1]
            elif uri.startswith('files/'):
                file_id = uri.replace('files/', '')
            
            if not file_id:
                raise Exception(f"æ— æ³•ä»URIä¸­æå–æ–‡ä»¶ID: {uri}")
            
            # ä½¿ç”¨Google Generative AI APIä¸‹è½½æ–‡ä»¶
            api_key = 'AIzaSyBWj4raKG-ayYkKOVP9eHSdpZO7oT7TuWo'
            download_url = f'https://generativelanguage.googleapis.com/v1beta/files/{file_id}?key={api_key}&alt=media'
            
            # ä¸‹è½½æ–‡ä»¶
            print(f"ğŸ“¥ ä¸‹è½½ä¸­: {uri} -> {local_filepath}")
            # é…ç½®ä»£ç†ï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
            proxies = {}
            if HTTP_PROXY or HTTPS_PROXY:
                if HTTP_PROXY:
                    proxies['http'] = HTTP_PROXY
                if HTTPS_PROXY:
                    proxies['https'] = HTTPS_PROXY
                elif HTTP_PROXY:
                    proxies['https'] = HTTP_PROXY
                print(f"ğŸŒ ä½¿ç”¨ä»£ç†ä¸‹è½½: {proxies}")
            response = requests.get(download_url, stream=True, timeout=600, proxies=proxies, verify=False)  # 10åˆ†é’Ÿè¶…æ—¶ï¼Œç¦ç”¨SSLéªŒè¯
            response.raise_for_status()
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('content-length', 0))
            if total_size > 0:
                print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {total_size / (1024*1024):.2f} MB")
            
            # å†™å…¥æ–‡ä»¶
            downloaded_size = 0
            with open(local_filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        if total_size > 0:
                            progress = (downloaded_size / total_size) * 100
                            if downloaded_size % (10 * 1024 * 1024) == 0:  # æ¯10MBæ‰“å°ä¸€æ¬¡
                                print(f"ğŸ“¥ ä¸‹è½½è¿›åº¦: {progress:.1f}% ({downloaded_size / (1024*1024):.2f} MB / {total_size / (1024*1024):.2f} MB)")
            
            print(f"âœ… è°·æ­Œå­˜å‚¨æ–‡ä»¶ä¸‹è½½å®Œæˆ: {file_path_or_name} ({downloaded_size / (1024*1024):.2f} MB)")
            return file_path_or_name
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½è°·æ­Œå­˜å‚¨æ–‡ä»¶å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise Exception(f"ä»è°·æ­Œå­˜å‚¨ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}")


@app.route('/postVideo', methods=['POST'])
def postVideo():
    try:
        # è·å–JSONæ•°æ®
        data = request.get_json()

        # ä»JSONæ•°æ®ä¸­æå–fileListå’ŒaccountList
        file_list = data.get('fileList', [])
        account_list = data.get('accountList', [])
        type = data.get('type')
        title = data.get('title')
        tags = data.get('tags')
        content = data.get('content', '') or data.get('desc', '')  # æ”¯æŒcontentå’Œdescä¸¤ç§å­—æ®µå
        category = data.get('category')
        enableTimer = data.get('enableTimer')
        if category == 0:
            category = None
        productLink = data.get('productLink', '')
        productTitle = data.get('productTitle', '')
        thumbnail_path = data.get('thumbnail', '')
        is_draft = data.get('isDraft', False)  # æ–°å¢å‚æ•°ï¼šæ˜¯å¦ä¿å­˜ä¸ºè‰ç¨¿

        videos_per_day = data.get('videosPerDay')
        daily_times = data.get('dailyTimes')
        start_days = data.get('startDays')
        
        # å¤„ç†fileListï¼šå¦‚æœæ˜¯URLæˆ–è°·æ­Œå­˜å‚¨æ–‡ä»¶ï¼Œå…ˆä¸‹è½½åˆ°æœ¬åœ°
        processed_file_list = []
        downloaded_files = []  # è®°å½•ä¸‹è½½çš„æ–‡ä»¶ï¼Œç”¨äºåç»­æ¸…ç†ï¼ˆå¯é€‰ï¼‰
        
        for file_item in file_list:
            # åˆ¤æ–­æ˜¯å¦æ˜¯URLï¼ˆhttpæˆ–httpså¼€å¤´ï¼‰
            if isinstance(file_item, str) and (file_item.startswith('http://') or file_item.startswith('https://')):
                print(f"ğŸ”— æ£€æµ‹åˆ°URLæ ¼å¼çš„è§†é¢‘: {file_item}")
                try:
                    # ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°
                    local_filename = download_video_from_url(file_item)
                    processed_file_list.append(local_filename)
                    downloaded_files.append(local_filename)
                    print(f"âœ… URLè§†é¢‘å·²ä¸‹è½½å¹¶æ·»åŠ åˆ°å‘å¸ƒåˆ—è¡¨: {local_filename}")
                except Exception as e:
                    print(f"âŒ ä¸‹è½½URLè§†é¢‘å¤±è´¥: {str(e)}")
                    raise Exception(f"ä¸‹è½½è§†é¢‘å¤±è´¥: {str(e)}")
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯è°·æ­Œå­˜å‚¨æ–‡ä»¶ï¼Œå¦‚æœæ˜¯åˆ™å…ˆä¸‹è½½åˆ°æœ¬åœ°
                try:
                    print(f"ğŸ“ æ£€æŸ¥æ–‡ä»¶: {file_item}")
                    local_filename = download_google_storage_file(file_item)
                    processed_file_list.append(local_filename)
                    # å¦‚æœæ–‡ä»¶è¢«ä¸‹è½½ï¼Œè®°å½•åˆ°ä¸‹è½½åˆ—è¡¨
                    if local_filename in downloaded_files or file_item != local_filename:
                        downloaded_files.append(local_filename)
                    print(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {local_filename}")
                except FileNotFoundError as e:
                    # æ–‡ä»¶ä¸å­˜åœ¨ï¼ŒæŠ›å‡ºé”™è¯¯
                    print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {str(e)}")
                    raise Exception(f"æ–‡ä»¶ä¸å­˜åœ¨: {str(e)}")
                except Exception as e:
                    # å…¶ä»–é”™è¯¯ï¼ˆå¯èƒ½æ˜¯ä¸‹è½½è°·æ­Œå­˜å‚¨æ–‡ä»¶å¤±è´¥ï¼‰
                    print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}")
                    raise Exception(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        # æ‰“å°å¤„ç†åçš„æ–‡ä»¶åˆ—è¡¨
        print("=" * 50)
        print("[postVideo] å¤„ç†åçš„æ–‡ä»¶åˆ—è¡¨:", processed_file_list)
        print("[postVideo] è´¦å·åˆ—è¡¨:", account_list)
        print("[postVideo] å¹³å°ç±»å‹ (type):", type)
        print("[postVideo] æ ‡é¢˜:", title)
        print("[postVideo] æ ‡ç­¾:", tags)
        print("[postVideo] å®šæ—¶å‘å¸ƒ:", enableTimer)
        print("=" * 50)
        
        # éªŒè¯å¤„ç†åçš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        for file_item in processed_file_list:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨äº videoFile ç›®å½•
            video_file_path = Path(BASE_DIR / "videoFile" / file_item)
            if not video_file_path.exists():
                print(f"âš ï¸ [postVideo] è­¦å‘Šï¼šæ–‡ä»¶ä¸å­˜åœ¨äº videoFile ç›®å½•: {video_file_path}")
                # å°è¯•å…¶ä»–ç›®å½•
                media_file_path = Path(BASE_DIR / "media" / file_item)
                root_file_path = Path(BASE_DIR / file_item)
                if media_file_path.exists():
                    print(f"âœ… [postVideo] æ–‡ä»¶å­˜åœ¨äº media ç›®å½•: {media_file_path}")
                elif root_file_path.exists():
                    print(f"âœ… [postVideo] æ–‡ä»¶å­˜åœ¨äºæ ¹ç›®å½•: {root_file_path}")
                else:
                    print(f"âŒ [postVideo] æ–‡ä»¶åœ¨æ‰€æœ‰ç›®å½•éƒ½ä¸å­˜åœ¨: {file_item}")
        
        # æ‰§è¡Œå‘å¸ƒä»»åŠ¡ï¼ˆä½¿ç”¨å¤„ç†åçš„æ–‡ä»¶åˆ—è¡¨ï¼‰
        if type == 1:
            post_video_xhs(title, processed_file_list, tags, account_list, category, enableTimer, videos_per_day, daily_times,
                              start_days, content=content)
        elif type == 2:
            post_video_tencent(title, processed_file_list, tags, account_list, category, enableTimer, videos_per_day, daily_times,
                              start_days, is_draft)
        elif type == 3:
            post_video_DouYin(title, processed_file_list, tags, account_list, category, enableTimer, videos_per_day, daily_times,
                      start_days, thumbnail_path, productLink, productTitle)
        elif type == 4:
            post_video_ks(title, processed_file_list, tags, account_list, category, enableTimer, videos_per_day, daily_times,
                      start_days)
        
        # è¿”å›å“åº”ç»™å®¢æˆ·ç«¯
        return jsonify(
            {
                "code": 200,
                "msg": "å‘å¸ƒä»»åŠ¡å·²æäº¤",
                "data": None
            }), 200
    except Exception as e:
        print(f"å‘å¸ƒè§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify(
            {
                "code": 500,
                "msg": f"å‘å¸ƒå¤±è´¥: {str(e)}",
                "data": None
            }), 500


@app.route('/postImageText', methods=['POST'])
def postImageText():
    """å°çº¢ä¹¦å›¾æ–‡è‡ªåŠ¨åŒ–å‘å¸ƒæ¥å£"""
    try:
        # è·å–JSONæ•°æ®
        data = request.get_json()

        # ä»JSONæ•°æ®ä¸­æå–å‚æ•°
        image_list = data.get('imageList', [])  # å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
        account_list = data.get('accountList', [])  # è´¦å·åˆ—è¡¨
        title = data.get('title', '')  # æ ‡é¢˜
        content = data.get('content', '')  # å†…å®¹/æè¿°
        tags = data.get('tags', [])  # æ ‡ç­¾åˆ—è¡¨
        enableTimer = data.get('enableTimer', False)  # æ˜¯å¦å¯ç”¨å®šæ—¶å‘å¸ƒ
        images_per_day = data.get('imagesPerDay', 1)  # æ¯å¤©å‘å¸ƒå›¾æ–‡æ•°
        daily_times = data.get('dailyTimes', [])  # æ¯æ—¥å‘å¸ƒæ—¶é—´
        start_days = data.get('startDays', 0)  # å¼€å§‹å¤©æ•°

        # å‚æ•°éªŒè¯
        if not image_list:
            return jsonify({
                "code": 400,
                "msg": "å›¾ç‰‡åˆ—è¡¨ä¸èƒ½ä¸ºç©º",
                "data": None
            }), 400

        if not account_list:
            return jsonify({
                "code": 400,
                "msg": "è´¦å·åˆ—è¡¨ä¸èƒ½ä¸ºç©º",
                "data": None
            }), 400

        if not title:
            return jsonify({
                "code": 400,
                "msg": "æ ‡é¢˜ä¸èƒ½ä¸ºç©º",
                "data": None
            }), 400

        # æ‰“å°è·å–åˆ°çš„æ•°æ®
        print("=" * 50)
        print("[postImageText] æ¥æ”¶åˆ°çš„æ•°æ®:")
        print("Image List:", image_list)
        print("Account List:", account_list)
        print("Title:", title)
        print("Content:", content)
        print("Content Length:", len(content) if content else 0)
        print("Content Is Empty:", not content or not content.strip())
        print("Tags:", tags)
        print("Enable Timer:", enableTimer)
        print("=" * 50)

        # æ‰§è¡Œå‘å¸ƒä»»åŠ¡
        post_image_text_xhs(
            title=title,
            content=content,
            image_files=image_list,
            tags=tags,
            account_file=account_list,
            enableTimer=enableTimer,
            images_per_day=images_per_day,
            daily_times=daily_times,
            start_days=start_days
        )

        # è¿”å›å“åº”ç»™å®¢æˆ·ç«¯
        return jsonify({
            "code": 200,
            "msg": "å›¾æ–‡å‘å¸ƒä»»åŠ¡å·²æäº¤",
            "data": None
        }), 200
    except Exception as e:
        print(f"å‘å¸ƒå›¾æ–‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "code": 500,
            "msg": f"å‘å¸ƒå¤±è´¥: {str(e)}",
            "data": None
        }), 500


@app.route('/updateUserinfo', methods=['POST'])
def updateUserinfo():
    # è·å–JSONæ•°æ®
    data = request.get_json()

    # ä»JSONæ•°æ®ä¸­æå– type å’Œ userName
    user_id = data.get('id')
    type = data.get('type')
    userName = data.get('userName')
    try:
        # è·å–æ•°æ®åº“è¿æ¥
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # æ›´æ–°æ•°æ®åº“è®°å½•
            cursor.execute('''
                           UPDATE user_info
                           SET type     = ?,
                               userName = ?
                           WHERE id = ?;
                           ''', (type, userName, user_id))
            conn.commit()

        return jsonify({
            "code": 200,
            "msg": "account update successfully",
            "data": None
        }), 200

    except Exception as e:
        return jsonify({
            "code": 500,
            "msg": str("update failed!"),
            "data": None
        }), 500

@app.route('/postVideoBatch', methods=['POST'])
def postVideoBatch():
    data_list = request.get_json()

    if not isinstance(data_list, list):
        return jsonify({"error": "Expected a JSON array"}), 400
    for data in data_list:
        # ä»JSONæ•°æ®ä¸­æå–fileListå’ŒaccountList
        file_list = data.get('fileList', [])
        account_list = data.get('accountList', [])
        type = data.get('type')
        title = data.get('title')
        tags = data.get('tags')
        category = data.get('category')
        enableTimer = data.get('enableTimer')
        if category == 0:
            category = None
        productLink = data.get('productLink', '')
        productTitle = data.get('productTitle', '')

        videos_per_day = data.get('videosPerDay')
        daily_times = data.get('dailyTimes')
        start_days = data.get('startDays')
        # æ‰“å°è·å–åˆ°çš„æ•°æ®ï¼ˆä»…ä½œä¸ºç¤ºä¾‹ï¼‰
        print("File List:", file_list)
        print("Account List:", account_list)
        if type == 1:
            return
        elif type == 2:
            post_video_tencent(title, file_list, tags, account_list, category, enableTimer, videos_per_day, daily_times,
                              start_days)
        elif type == 3:
            post_video_DouYin(title, file_list, tags, account_list, category, enableTimer, videos_per_day, daily_times,
                      start_days, productLink, productTitle)
        elif type == 4:
            post_video_ks(title, file_list, tags, account_list, category, enableTimer, videos_per_day, daily_times,
                      start_days)
    # è¿”å›å“åº”ç»™å®¢æˆ·ç«¯
    return jsonify(
        {
            "code": 200,
            "msg": None,
            "data": None
        }), 200

# Cookieæ–‡ä»¶ä¸Šä¼ API
@app.route('/uploadCookie', methods=['POST'])
def upload_cookie():
    try:
        if 'file' not in request.files:
            return jsonify({
                "code": 500,
                "msg": "æ²¡æœ‰æ‰¾åˆ°Cookieæ–‡ä»¶",
                "data": None
            }), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({
                "code": 500,
                "msg": "Cookieæ–‡ä»¶åä¸èƒ½ä¸ºç©º",
                "data": None
            }), 400

        if not file.filename.endswith('.json'):
            return jsonify({
                "code": 500,
                "msg": "Cookieæ–‡ä»¶å¿…é¡»æ˜¯JSONæ ¼å¼",
                "data": None
            }), 400

        # è·å–è´¦å·ä¿¡æ¯
        account_id = request.form.get('id')
        platform = request.form.get('platform')

        if not account_id or not platform:
            return jsonify({
                "code": 500,
                "msg": "ç¼ºå°‘è´¦å·IDæˆ–å¹³å°ä¿¡æ¯",
                "data": None
            }), 400

        # ä»æ•°æ®åº“è·å–è´¦å·çš„æ–‡ä»¶è·¯å¾„
        with sqlite3.connect(Path(BASE_DIR / "db" / "database.db")) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            cursor.execute('SELECT filePath FROM user_info WHERE id = ?', (account_id,))
            result = cursor.fetchone()

        if not result:
            return jsonify({
                "code": 500,
                "msg": "è´¦å·ä¸å­˜åœ¨",
                "data": None
            }), 404

        # ä¿å­˜ä¸Šä¼ çš„Cookieæ–‡ä»¶åˆ°å¯¹åº”è·¯å¾„
        cookie_file_path = Path(BASE_DIR / "cookiesFile" / result['filePath'])
        cookie_file_path.parent.mkdir(parents=True, exist_ok=True)

        file.save(str(cookie_file_path))

        # æ›´æ–°æ•°æ®åº“ä¸­çš„è´¦å·ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œæ¯”å¦‚æ›´æ–°æ›´æ–°æ—¶é—´ï¼‰
        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ é¢å¤–çš„å¤„ç†é€»è¾‘

        return jsonify({
            "code": 200,
            "msg": "Cookieæ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
            "data": None
        }), 200

    except Exception as e:
        print(f"ä¸Šä¼ Cookieæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "code": 500,
            "msg": f"ä¸Šä¼ Cookieæ–‡ä»¶å¤±è´¥: {str(e)}",
            "data": None
        }), 500


# Cookieæ–‡ä»¶ä¸‹è½½API
@app.route('/downloadCookie', methods=['GET'])
def download_cookie():
    try:
        file_path = request.args.get('filePath')
        if not file_path:
            return jsonify({
                "code": 500,
                "msg": "ç¼ºå°‘æ–‡ä»¶è·¯å¾„å‚æ•°",
                "data": None
            }), 400

        # éªŒè¯æ–‡ä»¶è·¯å¾„çš„å®‰å…¨æ€§ï¼Œé˜²æ­¢è·¯å¾„éå†æ”»å‡»
        cookie_file_path = Path(BASE_DIR / "cookiesFile" / file_path).resolve()
        base_path = Path(BASE_DIR / "cookiesFile").resolve()

        if not cookie_file_path.is_relative_to(base_path):
            return jsonify({
                "code": 500,
                "msg": "éæ³•æ–‡ä»¶è·¯å¾„",
                "data": None
            }), 400

        if not cookie_file_path.exists():
            return jsonify({
                "code": 500,
                "msg": "Cookieæ–‡ä»¶ä¸å­˜åœ¨",
                "data": None
            }), 404

        # è¿”å›æ–‡ä»¶
        return send_from_directory(
            directory=str(cookie_file_path.parent),
            path=cookie_file_path.name,
            as_attachment=True
        )

    except Exception as e:
        print(f"ä¸‹è½½Cookieæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "code": 500,
            "msg": f"ä¸‹è½½Cookieæ–‡ä»¶å¤±è´¥: {str(e)}",
            "data": None
        }), 500


# åŒ…è£…å‡½æ•°ï¼šåœ¨çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
def run_async_function(type, id, status_queue, browser_context_storage=None, automation_tool='playwright'):
    print(f"[å¼‚æ­¥ä»»åŠ¡] å¼€å§‹æ‰§è¡Œç™»å½•ä»»åŠ¡ - type: {type}, id: {repr(id)}, automation_tool: {automation_tool}", flush=True)
    try:
        if type == '1':
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(xiaohongshu_cookie_gen(id, status_queue))
            loop.close()
        elif type == '2':
            # è§†é¢‘å·ç™»å½•ï¼šä½¿ç”¨ myUtils.login.get_tencent_cookieï¼ˆä¸å®˜æ–¹ä»“åº“ä¿æŒä¸€è‡´ï¼‰
            import os
            original_tool = os.environ.get('AUTOMATION_TOOL')
            os.environ['AUTOMATION_TOOL'] = automation_tool
            print(f"[å¼‚æ­¥ä»»åŠ¡] ä¸ºæœ¬æ¬¡ç™»å½•è®¾ç½®è‡ªåŠ¨åŒ–å·¥å…·: {automation_tool.upper()}", flush=True)
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            # å½“å‰ç»Ÿä¸€ä½¿ç”¨ Playwright ç‰ˆæœ¬å®ç°ï¼Œä¸å†ä¾èµ– login_wrapper
            loop.run_until_complete(get_tencent_cookie(id, status_queue))
            loop.close()
            
            # æ¢å¤åŸæ¥çš„ç¯å¢ƒå˜é‡
            if original_tool is not None:
                os.environ['AUTOMATION_TOOL'] = original_tool
            elif 'AUTOMATION_TOOL' in os.environ:
                del os.environ['AUTOMATION_TOOL']
        elif type == '3':
            print(f"[å¼‚æ­¥ä»»åŠ¡] è°ƒç”¨æŠ–éŸ³ç™»å½•å‡½æ•°ï¼Œä¼ é€’è´¦å·åç§°: {repr(id)}")
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(douyin_cookie_gen(id, status_queue))
            loop.close()
            print(f"[å¼‚æ­¥ä»»åŠ¡] æŠ–éŸ³ç™»å½•ä»»åŠ¡å®Œæˆ")
        elif type == '4':
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(get_ks_cookie(id, status_queue))
            loop.close()
        elif type == '5':
            print(f"[å¼‚æ­¥ä»»åŠ¡] è°ƒç”¨Bç«™ç™»å½•å‡½æ•°ï¼Œä¼ é€’è´¦å·åç§°: {repr(id)}")
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(bilibili_cookie_gen(id, status_queue))
            loop.close()
            print(f"[å¼‚æ­¥ä»»åŠ¡] Bç«™ç™»å½•ä»»åŠ¡å®Œæˆ")
    except Exception as e:
        print(f"[å¼‚æ­¥ä»»åŠ¡] ç™»å½•ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        status_queue.put("500")

# SSE æµç”Ÿæˆå™¨å‡½æ•°
def sse_stream(status_queue):
    print(f"[SSEæµ] å¼€å§‹SSEæµç”Ÿæˆå™¨ - æ¥å£: /login (SSEæµ)")
    final_status_sent = False
    last_heartbeat = time.time()
    heartbeat_interval = 15  # æ¯15ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
    
    while True:
        current_time = time.time()
        
        # å‘é€å¿ƒè·³ä¿æŒè¿æ¥ï¼ˆæ¯15ç§’ä¸€æ¬¡ï¼‰
        if current_time - last_heartbeat >= heartbeat_interval:
            try:
                yield f": heartbeat\n\n"  # SSEæ³¨é‡Šï¼Œç”¨äºä¿æŒè¿æ¥
                last_heartbeat = current_time
                print(f"[SSEæµ] å‘é€å¿ƒè·³ä¿æŒè¿æ¥")
            except Exception as e:
                print(f"[SSEæµ] å‘é€å¿ƒè·³å¤±è´¥: {e}")
                break
        
        if not status_queue.empty():
            msg = status_queue.get()
            msg_str = str(msg)
            print(f"[SSEæµ] ä»é˜Ÿåˆ—è·å–æ¶ˆæ¯: {msg_str[:100] if len(msg_str) > 100 else msg_str}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯Cookieæ•°æ®
            if msg_str.startswith("cookie:"):
                cookie_data_str = msg_str[7:]  # å»æ‰ 'cookie:' å‰ç¼€
                print(f"[SSEæµ] ğŸª æ£€æµ‹åˆ°Cookieæ•°æ®ï¼Œå‡†å¤‡é€šè¿‡SSEæµå‘é€")
                print(f"[SSEæµ] Cookieæ•°æ®å¤§å°: {len(cookie_data_str)} å­—èŠ‚")
                try:
                    import json
                    cookie_data = json.loads(cookie_data_str)
                    print(f"[SSEæµ] Cookieæ•°æ®è¯¦æƒ… - è´¦å·: {cookie_data.get('userName', 'N/A')}, æ–‡ä»¶è·¯å¾„: {cookie_data.get('filePath', 'N/A')}, Cookieæ•°é‡: {len(cookie_data.get('cookies', []))}")
                except:
                    print(f"[SSEæµ] âš ï¸ æ— æ³•è§£æCookieæ•°æ®JSON")
            
            try:
                yield f"data: {msg}\n\n"
                
                # å¦‚æœæ˜¯Cookieæ•°æ®ï¼Œè®°å½•å‘é€æˆåŠŸ
                if msg_str.startswith("cookie:"):
                    print(f"[SSEæµ] âœ… Cookieæ•°æ®å·²é€šè¿‡SSEæµå‘é€ç»™å®¢æˆ·ç«¯")
                
                # å¦‚æœæ”¶åˆ°æœ€ç»ˆçŠ¶æ€ç ï¼ˆ200æˆ–500ï¼‰ï¼Œæ ‡è®°å·²å‘é€ï¼Œä½†ç»§ç»­ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿å‰ç«¯æ”¶åˆ°
                if msg_str == "200" or msg_str == "500":
                    print(f"[SSEæµ] æ”¶åˆ°æœ€ç»ˆçŠ¶æ€ç  {msg_str}ï¼Œå·²å‘é€ç»™å®¢æˆ·ç«¯")
                    final_status_sent = True
                    # ç»§ç»­ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ¶ˆæ¯è¢«å‘é€ï¼Œç„¶åç»“æŸ
                    time.sleep(0.5)
                    break
            except Exception as e:
                print(f"[SSEæµ] å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
                if msg_str.startswith("cookie:"):
                    print(f"[SSEæµ] âŒ Cookieæ•°æ®å‘é€å¤±è´¥: {e}")
                break
        else:
            # å¦‚æœå·²ç»å‘é€äº†æœ€ç»ˆçŠ¶æ€ç ï¼Œä¸”é˜Ÿåˆ—ä¸ºç©ºï¼Œå¯ä»¥ç»“æŸ
            if final_status_sent:
                print(f"[SSEæµ] æœ€ç»ˆçŠ¶æ€ç å·²å‘é€ï¼Œé˜Ÿåˆ—ä¸ºç©ºï¼Œç»“æŸSSEæµ")
                break
            # é¿å… CPU å æ»¡ï¼Œä½†ä¸è¦é˜»å¡å¤ªä¹…ï¼Œä»¥ä¾¿åŠæ—¶å‘é€å¿ƒè·³
            time.sleep(0.5)

# å›¾æ–‡ç”Ÿæˆwebhookä»£ç†æ¥å£
@app.route('/generateImageText', methods=['POST'])
def generate_image_text():
    """
    ä»£ç†è½¬å‘å›¾æ–‡ç”Ÿæˆè¯·æ±‚åˆ°webhook
    è§£å†³å‰ç«¯CORSè·¨åŸŸé—®é¢˜
    """
    try:
        # è·å–å‰ç«¯å‘é€çš„æ•°æ®
        data = request.get_json()
        
        # webhookç›®æ ‡åœ°å€ï¼ˆæµ‹è¯•æ¨¡å¼ - å›¾æ–‡å†…å®¹ç”Ÿæˆï¼‰
        webhook_url = 'https://aicode.ltd/webhook-test/c155e570-faf5-4351-b1bd-7b908cf6db36'
        
        # è½¬å‘POSTè¯·æ±‚åˆ°webhookï¼ˆå¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºAIç”Ÿæˆéœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰
        response = requests.post(
            webhook_url,
            json=data,
            headers={'Content-Type': 'application/json'},
            timeout=120  # 120ç§’è¶…æ—¶ï¼Œé€‚åº”AIç”Ÿæˆå†…å®¹çš„è€—æ—¶
        )
        
        # è¿”å›webhookçš„å“åº”
        try:
            result = response.json()
        except:
            result = {'message': 'è¯·æ±‚æˆåŠŸ', 'status': response.status_code}
        
        return jsonify({
            'code': 200,
            'data': result,
            'msg': 'æˆåŠŸ'
        })
        
    except requests.exceptions.Timeout:
        return jsonify({
            'code': 500,
            'data': None,
            'msg': 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•'
        }), 500
        
    except requests.exceptions.RequestException as e:
        return jsonify({
            'code': 500,
            'data': None,
            'msg': f'è¯·æ±‚å¤±è´¥: {str(e)}'
        }), 500
        
    except Exception as e:
        return jsonify({
            'code': 500,
            'data': None,
            'msg': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0' ,port=5409)
